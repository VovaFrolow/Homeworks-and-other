{"cells":[{"cell_type":"markdown","metadata":{"id":"xK-KnMSqbfgV"},"source":["# **Важно!**\n","\n","Домашнее задание состоит из нескольких задач, которые вам нужно решить.\n","*   Баллы выставляются по принципу выполнено/невыполнено.\n","*   За каждую выполненую задачу вы получаете баллы (количество баллов за задание указано в скобках).\n","\n","**Инструкция выполнения:** Выполните задания в этом же ноутбуке (места под решения **КАЖДОЙ** задачи обозначены как **#НАЧАЛО ВАШЕГО РЕШЕНИЯ** и **#КОНЕЦ ВАШЕГО РЕШЕНИЯ**)\n","\n","**Как отправить задание на проверку:** Вам необходимо сохранить ваше решение в данном блокноте и отправить итоговый **файл .IPYNB** на учебной платформе в **стандартную форму сдачи домашнего задания.**\n","\n","**Срок проверки преподавателем:** домашнее задание проверяется **в течение 3 дней после дедлайна сдачи** с предоставлением обратной связи\n","\n","# **Прежде чем проверять задания:**\n","\n","1. Перезапустите **ядро (restart the kernel)**: в меню, выбрать **Ядро (Kernel)**\n","→ **Перезапустить (Restart)**\n","2. Затем **Выполнить** **все ячейки (run all cells)**: в меню, выбрать **Ячейка (Cell)**\n","→ **Запустить все (Run All)**.\n","\n","После ячеек с заданием следуют ячейки с проверкой **с помощью assert.**\n","\n","Если в коде есть ошибки, assert выведет уведомление об ошибке.\n","\n","Если в коде нет ошибок, assert отработает без вывода дополнительной информации."]},{"cell_type":"markdown","metadata":{"id":"-E4LzY09bfga"},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ptVSdnh0bfgb"},"outputs":[],"source":["import math\n","import re\n","from random import randrange, shuffle, random, randint\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"6d86a1487b0c6217219e8a8543a371a1","grade":true,"grade_id":"cell-71dc2f298aaab2b9","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"Ws7c_C92bfgd"},"outputs":[],"source":["\"\"\"\n","Задание 1 (1 балл): Генерация пакетов данных для обучения модели BERT\n","\n","**Цель задания:** Написать код, который генерирует пакеты данных для обучения модели BERT с использованием Python и библиотеки NumPy.\n","\n","**Задачи:**\n","1. Сформировать пустой список `batch` для хранения пакетов данных.\n","2. Инициализировать счетчики `positive` и `negative` для отслеживания положительных и отрицательных пар предложений.\n","3. В цикле, пока количество положительных и отрицательных пар в `batch` не достигнет заданного размера (`batch_size/2`), выполнить следующие шаги:\n","    - Выбрать случайные индексы двух предложений из списка `sentences`.\n","    - Получить сами предложения по выбранным индексам и сохранить их в переменные `tokens_a` и `tokens_b`.\n","    - Собрать входные данные для модели BERT, добавив специальные токены `[CLS]` и `[SEP]`. Используйте переменные `input_ids` и `segment_ids`\n","    для этой цели.\n","    - Реализовать маскирование токенов (MASK LM):\n","        - Определить количество токенов, которые будут маскированы (подставлены вместо них `[MASK]`).\n","        - Создать список кандидатов для маскирования (`cand_maked_pos`) и перемешать его.\n","        - Заполнить списки `masked_tokens` и `masked_pos` маскированными токенами и их позициями.\n","        - С вероятностью 80%, замаскировать токен, а с вероятностью 10%, заменить его случайным словом из словаря.\n","    - Дополнить последовательности нулями (`0`) до максимальной длины (`maxlen`).\n","    - Дополнить нулями маскированные токены и их позиции, чтобы их количество соответствовало максимально возможному (`max_pred`).\n","    - Определить, являются ли два предложения последовательными (`IsNext`) или нет (`NotNext`) на основе индексов предложений и счетчиков `positive`\n","    и `negative`.\n","    - Добавить полученные данные в список `batch` как положительную пару (`IsNext`) или отрицательную пару (`NotNext`).\n","    - Увеличить соответствующий счетчик (`positive` или `negative`) на `1`.\n","4. Вернуть сформированный список `batch` как результат выполнения функции.\n","\n","**Примечания:**\n","- Задания выполняются в рамках задачи Next Sentence Prediction (NSP) для обучения модели BERT.\n","- Вы можете использовать функции и библиотеки Python, такие как `randrange`, `shuffle`, `random`, `randint`, `extend` и другие, для реализации\n","задачи.\n","- Весь необходимый функционал для работы с данными и списками будет предоставлен вам. Ваша задача - реализовать собственно формирование\n","пакетов данных на основе предоставленного кода и комментариев.\n","\"\"\"\n","\n","def make_batch():\n","    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","    batch = []\n","    positive = 0\n","    negative = 0\n","    while positive < batch_size/2 or negative < batch_size/2:\n","        idx1, idx2 = randrange(len(sentences)), randrange(len(sentences))\n","        tokens_a, tokens_b = token_list[idx1], token_list[idx2]\n","        input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']]\n","        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n","\n","        n_pred = min(max_pred, max(1, int(round(len(input_ids) * 0.15))))\n","        cand_maked_pos = [\n","            i for i, token in enumerate(input_ids) if token != word_dict['[CLS]'] and\n","            token != word_dict['[SEP]']\n","        ]\n","        shuffle(cand_maked_pos)\n","        masked_tokens, masked_pos = [], []\n","        for pos in cand_maked_pos[:n_pred]:\n","            masked_pos.append(pos)\n","            masked_tokens.append(input_ids[pos])\n","            if random() < 0.8:\n","                input_ids[pos] = word_dict['[MASK]']\n","            elif random() < 0.5:\n","                index = randint(0, vocab_size-1)\n","                input_ids[pos] = word_dict[number_dict[index]]\n","\n","        n_pad = maxlen - len(input_ids)\n","        input_ids.extend([0] * n_pad)\n","        segment_ids.extend([0] * n_pad)\n","\n","        if max_pred > n_pred:\n","            n_pad = max_pred - n_pred\n","            masked_tokens.extend([0] * n_pad)\n","            masked_pos.extend([0] * n_pad)\n","\n","        if idx1 + 1 == idx2 and positive < batch_size/2:\n","            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True])\n","            positive += 1\n","        elif idx1 + 1 != idx2 and negative < batch_size/2:\n","            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False])\n","            negative += 1\n","\n","    return batch\n","    # КОНЕЦ ВАШЕГО РЕШЕНИЯ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WkhLM9ADbfge"},"outputs":[],"source":["def get_attn_pad_mask(seq_q, seq_k):\n","    \"\"\"\n","    Функция для создания маски внимания, которая скрывает внимание на токенах-заполнителях (PAD).\n","\n","    Args:\n","    - seq_q: Тензор с представлением запросов (batch_size x len_q).\n","    - seq_k: Тензор с представлением ключей (batch_size x len_k).\n","\n","    Returns:\n","    - pad_attn_mask: Маска для внимания, скрывающая PAD-токены (batch_size x 1 x len_k(=len_q)).\n","    \"\"\"\n","    batch_size, len_q = seq_q.size()\n","    batch_size, len_k = seq_k.size()\n","\n","    # Создаем маску, в которой значение True (1) будет соответствовать PAD-токенам.\n","    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), где 1 означает маскирование\n","\n","    # Расширяем маску до размерности batch_size x len_q x len_k, чтобы ее можно было использовать для маскирования внимания.\n","    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k\n","\n","\n","def gelu(x):\n","    \"\"\"\n","    Реализация активационной функции GELU (Gaussian Error Linear Unit) от Hugging Face.\n","\n","    Args:\n","    - x: Входной тензор.\n","\n","    Returns:\n","    - Результат применения функции GELU к входному тензору.\n","    \"\"\"\n","    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTD-CZKubfge"},"outputs":[],"source":["class Embedding(nn.Module):\n","    def __init__(self):\n","        super(Embedding, self).__init__()\n","        self.tok_embed = nn.Embedding(vocab_size, d_model)  # Токенное встраивание\n","        self.pos_embed = nn.Embedding(maxlen, d_model)  # Встраивание позиции\n","        self.seg_embed = nn.Embedding(n_segments, d_model)  # Встраивание сегмента (типа токена)\n","        self.norm = nn.LayerNorm(d_model)\n","\n","    def forward(self, x, seg):\n","        seq_len = x.size(1)\n","        pos = torch.arange(seq_len, dtype=torch.long)\n","        pos = pos.unsqueeze(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n","        # Общее встраивание, включая токены, позиции и сегменты\n","        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n","        return self.norm(embedding)"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"b237d4ea5134bb920276808a0b42c51d","grade":true,"grade_id":"cell-cf85318c5b529648","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"kTNu6Qdebfgf"},"outputs":[],"source":["\"\"\"\n","## Задание 2 (1 балл): Реализация класса ScaledDotProductAttention\n","\n","**Цель задания:** Написать класс `ScaledDotProductAttention`, который реализует механизм внимания с масштабированным скалярным произведением.\n","\n","**Задачи:**\n","1. Создать класс `ScaledDotProductAttention`, который наследует `nn.Module` из библиотеки PyTorch.\n","2. В методе `forward` класса `ScaledDotProductAttention`, выполнить следующие действия:\n","   - Вычислите оценки (scores) как скалярное произведение матрицы запросов (Q) и транспонированной матрицы ключей (K).\n","   Масштабируйте оценки на обратный квадратный корень от размерности `d_k`.\n","   - Примените маску внимания (`attn_mask`) для скрытия определенных значений в оценках (scores).\n","   Для этого используйте метод `masked_fill_`, который заменяет элементы тензора на заданное значение, где маска равна 1.\n","   - Примените функцию softmax для вычисления весов внимания, которые определяют, насколько каждый элемент входных данных важен.\n","   - Вычислите контекст путем взвешенной суммы значений (V) с использованием весов внимания.\n","   - Верните контекст и веса внимания.\n","\"\"\"\n","\n","class ScaledDotProductAttention(nn.Module):\n","    def __init__(self):\n","        super(ScaledDotProductAttention, self).__init__()\n","\n","    def forward(self, Q, K, V, attn_mask):\n","        # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)\n","        scores.masked_fill_(attn_mask, -1e9)\n","        weights = nn.Softmax(dim=-1)(scores)\n","        context = torch.matmul(weights, V)\n","\n","        return context, weights\n","        # КОНЕЦ ВАШЕГО РЕШЕНИЯ"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"41f95d091fe36fc19f189fd8b9e7ff55","grade":true,"grade_id":"cell-03e0e6e6528c749f","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"juvFTK1gbfgg"},"outputs":[],"source":["\"\"\"\n","## Задание 3 (1 балл): Реализация класса MultiHeadAttention\n","\n","**Цель задания:** Написать класс `MultiHeadAttention`, который реализует многоголовое внимание (Multi-Head Attention) в модели трансформера.\n","\n","**Задачи:**\n","1. Создать класс `MultiHeadAttention`, который наследует `nn.Module` из библиотеки PyTorch.\n","2. В конструкторе класса `MultiHeadAttention`, определить следующие атрибуты:\n","   - `W_Q`: Используйте линейный слой `nn.Linear` для создания преобразования запросов (Q).\n","   Размерность выхода должна быть `d_k * n_heads`. Прокомментируйте это как \"Преобразование запросов\".\n","   - `W_K`: Используйте линейный слой `nn.Linear` для создания преобразования ключей (K).\n","   Размерность выхода должна быть `d_k * n_heads`. Прокомментируйте это как \"Преобразование ключей\".\n","   - `W_V`: Используйте линейный слой `nn.Linear` для создания преобразования значений (V).\n","   Размерность выхода должна быть `d_v * n_heads`. Прокомментируйте это как \"Преобразование значений\".\n","3. В методе `forward` класса `MultiHeadAttention`, выполнить следующие действия:\n","   - Сохраните оригинальные запросы `Q` и определите размер пакета (batch_size).\n","   - Преобразуйте запросы, ключи и значения (`Q`, `K`, `V`) с использованием линейных преобразований `W_Q`, `W_K` и `W_V`,\n","   учитывая многие головы. Результаты преобразований должны быть разделены на головы и транспонированы.\n","   - Создайте маску внимания (`attn_mask`) с учетом входной маски `attn_mask` и повторите ее для каждой головы.\n","   - Примените механизм внимания (`ScaledDotProductAttention`) к головам, передав преобразованные запросы, ключи, значения и маску внимания.\n","   - Транспонируйте и объедините результаты голов для получения контекста.\n","   - Примените линейное преобразование и слой нормализации к контексту.\n","   - Верните нормализованный контекст и веса внимания.\n","\"\"\"\n","\n","class MultiHeadAttention(nn.Module):\n","    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","    def __init__(self):\n","        super(MultiHeadAttention, self).__init__()\n","        self.W_Q = nn.Linear(d_model, d_k*n_heads)   # Преобразование запросов\n","        self.W_K = nn.Linear(d_model, d_k*n_heads)   # Преобразование ключей\n","        self.W_V = nn.Linear(d_model, d_v*n_heads)   # Преобразование значений\n","\n","    def forward(self, Q, K, V, attn_mask):\n","        residual, batch_size = Q, Q.size(0)\n","        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n","        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n","        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1, 2)\n","\n","        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)\n","\n","        context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n","        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads*d_v)\n","        output = nn.Linear(n_heads*d_v, d_model)(context)\n","\n","        return nn.LayerNorm(d_model)(output+residual), attn\n","    # КОНЕЦ ВАШЕГО РЕШЕНИЯ"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"a8aa7542da018e4886bbb2201338e50c","grade":true,"grade_id":"cell-0829ddc4353a996e","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"J7L3liPobfgg"},"outputs":[],"source":["\"\"\"\n","## Задание 4 (1 балл): Реализация класса PoswiseFeedForwardNet\n","\n","**Цель задания:** Написать класс `PoswiseFeedForwardNet`, который реализует полносвязную нейронную сеть с прямым распространением\n","(Feed Forward Neural Network) в модели трансформера.\n","\n","**Задачи:**\n","1. Создать класс `PoswiseFeedForwardNet`, который наследует `nn.Module` из библиотеки PyTorch.\n","2. В конструкторе класса `PoswiseFeedForwardNet`, определить два атрибута:\n","   - `fc1`: Используйте линейный слой `nn.Linear`, чтобы создать первый линейный слой прямого распространения (feed-forward).\n","   Размерность входа должна быть `d_model`, а размерность выхода - `d_ff`. Прокомментируйте это как \"Первый линейный слой (прямого распространения)\".\n","   - `fc2`: Используйте линейный слой `nn.Linear`, чтобы создать второй линейный слой прямого распространения.\n","   Размерность входа должна быть `d_ff`, а размерность выхода - `d_model`. Прокомментируйте это как \"Второй линейный слой (прямого распространения)\".\n","3. В методе `forward` класса `PoswiseFeedForwardNet`, выполнить следующие действия:\n","   - Пропустите входные данные `x` через первый линейный слой `fc1`.\n","   - Примените функцию активации GELU (Gaussian Error Linear Unit) к результату первого линейного слоя.\n","   - Пропустите результат через второй линейный слой `fc2`.\n","   - Верните полученный результат в качестве выходных данных модели.\n","\"\"\"\n","\n","\n","class PoswiseFeedForwardNet(nn.Module):\n","    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","    def __init__(self):\n","        super(PoswiseFeedForwardNet, self).__init__()\n","        self.fc1 = nn.Linear(d_model, d_ff)   # Первый линейный слой (прямого распространения)\n","        self.fc2 = nn.Linear(d_ff, d_model)   # Второй линейный слой (прямого распространения)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        output = self.fc2(gelu(x))\n","\n","        return output\n","    # КОНЕЦ ВАШЕГО РЕШЕНИЯ"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"31b75810554dc7ff82fdf946ed9ee2d8","grade":true,"grade_id":"cell-4f4e36c132987802","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"mWmzyUoEbfgh"},"outputs":[],"source":["\"\"\"\n","## Задание 5 (1 балл): Реализация класса EncoderLayer\n","\n","**Цель задания:** Написать класс `EncoderLayer`, который представляет собой один слой кодировщика в модели трансформера.\n","\n","**Задачи:**\n","1. Создать класс `EncoderLayer`, который наследует `nn.Module` из библиотеки PyTorch.\n","2. В конструкторе класса `EncoderLayer`, определить два атрибута:\n","   - `enc_self_attn`: Используйте класс `MultiHeadAttention`, чтобы создать многоголовое внимание для кодировщика.\n","   Прокомментируйте это как \"Многоголовое внимание для кодировщика\".\n","   - `pos_ffn`: Используйте класс `PoswiseFeedForwardNet`, чтобы создать полносвязную нейронную сеть с прямым распространением.\n","   Прокомментируйте это как \"Полносвязная нейронная сеть с прямым распространением\".\n","3. В методе `forward` класса `EncoderLayer`, выполнить следующие действия:\n","   - Применить многоголовое внимание `enc_self_attn` для самокодирования кодировщика, используя входные данные\n","   `enc_inputs` в роли запросов, ключей и значений.\n","   - Применить полносвязную нейронную сеть с прямым распространением `pos_ffn` для обработки выходных данных многоголового внимания.\n","   - Вернуть обработанные данные и веса внимания.\n","\"\"\"\n","\n","class EncoderLayer(nn.Module):\n","    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","    def __init__(self):\n","        super(EncoderLayer, self).__init__()\n","        self.enc_self_attn = MultiHeadAttention()   # Многоголовое внимание для кодировщика\n","        self.pos_ffn = PoswiseFeedForwardNet()   # Полносвязная нейронная сеть с прямым распространением\n","\n","    def forward(self, enc_inputs, enc_self_attn_mask):\n","        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)\n","        enc_outputs = self.pos_ffn(enc_outputs)\n","\n","        return enc_outputs, attn\n","    # КОНЕЦ ВАШЕГО РЕШЕНИЯ"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"d98a6f55fb52dc4c307cba8439011204","grade":true,"grade_id":"cell-81ccedae031e4069","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"UT37Az2_bfgi"},"outputs":[],"source":["\"\"\"\n","**Задание 6 (1 балл): Реализация модели BERT**\n","\n","**Цель:** Ваша задача - реализовать модель BERT (Bidirectional Encoder Representations from Transformers) с использованием PyTorch.\n","\n","**Инструкции:**\n","\n","1. Ваша задача - реализовать класс BERT.\n","\n","Описание задания для студентов: Реализация модели BERT\n","\n","1. Создайте класс `BERT`, который будет наследоваться от `nn.Module`. В этом классе вы должны реализовать архитектуру BERT.\n","\n","2. В конструкторе класса `BERT`, выполните следующие шаги:\n","   - Создайте модуль встраивания (Embedding) и добавьте его в класс.\n","   - Создайте список слоев кодировщика (EncoderLayer) и добавьте его в класс. Количество слоев кодировщика (`n_layers`) можно задать в качестве аргумента конструктора.\n","   - Создайте линейный слой (`nn.Linear`) для извлечения признаков из первого токена (CLS) и добавьте функцию активации (гиперболический тангенс).\n","   - Создайте второй линейный слой для извлечения скрытых признаков из выхода трансформера на позициях маскированных токенов. В качестве функции активации используйте GELU (Gaussian Error Linear Unit).\n","   - Добавьте слой нормализации (LayerNorm) и линейный классификатор для задачи классификации.\n","\n","3. Реализуйте метод `forward`, который принимает входные данные (`input_ids`, `segment_ids`, `masked_pos`) и выполняет следующие действия:\n","   - Применяет входные данные через встраивание и кодировщик.\n","   - Извлекает признаки из первого токена (CLS) для классификации.\n","   - Извлекает скрытые признаки из выхода трансформера на позициях маскированных токенов.\n","   - Возвращает результаты классификации и предсказания маскированных токенов.\n","\n","4. Обратите внимание на использование функций активации, слоев нормализации и линейных слоев в методе `forward`.\n","\n","5. Создайте декодер, который будет использоваться совместно с встраиванием для задачи предсказания маскированных токенов.\n","\n","6. Установите веса декодера равными весам встраивания.\n","\n","7. Возвращайте результаты предсказания маскированных токенов и классификации.\n","\"\"\"\n","\n","\n","class BERT(nn.Module):\n","    # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","    def __init__(self):\n","        super(BERT, self).__init__()\n","        self.embedding = Embedding()\n","        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n","        self.linear1 = nn.Linear(d_model, d_model)\n","        self.tanh = nn.Tanh()\n","        self.linear2 = nn.Linear(d_model, d_model)\n","        self.gelu = gelu\n","        self.norm = nn.LayerNorm(d_model)\n","        self.classifier = nn.Linear(d_model, 2)\n","        # decoder\n","        embed_weight = self.embedding.tok_embed.weight\n","        n_vocab, n_dim = embed_weight.size()\n","        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n","        self.decoder.weight = embed_weight\n","        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n","\n","    def forward(self, input_ids, segment_ids, masked_pos):\n","        embedded = self.embedding(input_ids, segment_ids)\n","        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)\n","        for layer in self.layers:\n","            output, enc_self_attn = layer(embedded, enc_self_attn_mask)\n","\n","        h_pooled = self.tanh(self.linear1(output[:, 0]))\n","        logits_clf = self.classifier(h_pooled)\n","\n","        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1))\n","        h_masked = torch.gather(output, 1, masked_pos)\n","        h_masked = self.norm(self.gelu(self.linear2(h_masked)))\n","        logits_lm = self.decoder(h_masked) + self.decoder_bias\n","\n","        return logits_lm, logits_clf\n","    # КОНЕЦ ВАШЕГО РЕШЕНИЯ"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-NcXQGDbfgi","outputId":"b4812669-737c-4908-84b9-784b97297fbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Эпоха: 0010 функция потерь = 3.898372\n","Эпоха: 0020 функция потерь = 2.532009\n","Эпоха: 0030 функция потерь = 2.519258\n","Эпоха: 0040 функция потерь = 1.953122\n","Эпоха: 0050 функция потерь = 1.161394\n","Эпоха: 0060 функция потерь = 1.530854\n","Эпоха: 0070 функция потерь = 1.116969\n","Эпоха: 0080 функция потерь = 0.901022\n","Эпоха: 0090 функция потерь = 1.048926\n","Эпоха: 0100 функция потерь = 0.817799\n","Привет, как дела? Я - Ромео.\n","Привет, Ромео. Меня зовут Джульетта. Приятно познакомиться.\n","Приятно познакомиться. Как твои дела сегодня?\n","Здорово. Моя бейсбольная команда выиграла соревнование.\n","Поздравляю, Джульетта.\n","Спасибо, Ромео\n","['[CLS]', 'приятно', 'познакомиться', 'как', 'твои', 'дела', 'сегодня', '[SEP]', '[MASK]', 'ромео', 'меня', 'зовут', 'джульетта', '[MASK]', 'познакомиться', '[SEP]']\n","Список маскированных токенов:  [7, 10]\n","Предсказанный список маскированных токенов:  [7, 10]\n","isNext :  False\n","Предсказано isNext :  False\n"]}],"source":["# Параметры BERT\n","maxlen = 30  # максимальная длина\n","batch_size = 6\n","max_pred = 5  # максимальное количество предсказываемых токенов\n","n_layers = 6  # количество слоев в кодировщике\n","n_heads = 12  # количество голов в Multi-Head Attention\n","d_model = 768  # размер вложения\n","d_ff = 768 * 4  # 4*d_model, размер скрытого слоя FeedForward\n","d_k = d_v = 64  # размерности K(=Q), V\n","n_segments = 2\n","\n","text = (\n","    'Привет, как дела? Я - Ромео.\\n'\n","    'Привет, Ромео. Меня зовут Джульетта. Приятно познакомиться.\\n'\n","    'Приятно познакомиться. Как твои дела сегодня?\\n'\n","    'Здорово. Моя бейсбольная команда выиграла соревнование.\\n'\n","    'Поздравляю, Джульетта.\\n'\n","    'Спасибо, Ромео'\n",")\n","sentences = re.sub(\"[.,!?\\\\-]\", '', text.lower()).split('\\n')  # фильтруем '.', ',', '?', '!'\n","word_list = list(set(\" \".join(sentences).split()))\n","word_dict = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3}\n","for i, w in enumerate(word_list):\n","    word_dict[w] = i + 4\n","number_dict = {i: w for i, w in enumerate(word_dict)}\n","vocab_size = len(word_dict)\n","\n","token_list = list()\n","for sentence in sentences:\n","    arr = [word_dict[s] for s in sentence.split()]\n","    token_list.append(arr)\n","\n","model = BERT()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","batch = make_batch()\n","input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n","\n","for epoch in range(100):\n","    optimizer.zero_grad()\n","    logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n","    loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens)  # для маскированной модели языка\n","    loss_lm = (loss_lm.float()).mean()\n","    loss_clsf = criterion(logits_clsf, isNext)  # для классификации предложений\n","    loss = loss_lm + loss_clsf\n","    if (epoch + 1) % 10 == 0:\n","        print('Эпоха:', '%04d' % (epoch + 1), 'функция потерь =', '{:.6f}'.format(loss))\n","    loss.backward()\n","    optimizer.step()\n","\n","# Предсказание маскированных токенов и isNext\n","input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[0]))\n","print(text)\n","print([number_dict[w.item()] for w in input_ids[0] if number_dict[w.item()] != '[PAD]'])\n","\n","logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n","logits_lm = logits_lm.data.max(2)[1][0].data.numpy()\n","print('Список маскированных токенов: ', [pos.item() for pos in masked_tokens[0] if pos.item() != 0])\n","print('Предсказанный список маскированных токенов: ', [pos for pos in logits_lm if pos != 0])\n","\n","logits_clsf = logits_clsf.data.max(1)[1].data.numpy()[0]\n","print('isNext : ', True if isNext else False)\n","print('Предсказано isNext : ', True if logits_clsf else False)"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCmqSktJ6cD0","outputId":"10d78a8e-c50c-4b29-d988-0a2446921f80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"]}]},{"cell_type":"code","source":["!pip install accelerate -U"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4XKNHqm_-GO7","outputId":"af222dcc-15b5-4dbb-f7f6-855b5ef96305"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting accelerate\n","  Downloading accelerate-0.24.0-py3-none-any.whl (260 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.24.0\n"]}]},{"cell_type":"code","source":["!pip install transformers[torch]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubp0te4M-iPf","outputId":"5675f36c-6746-4057-f687-e2d8a7316d35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.34.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n","Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TwoE4sKAbfgj"},"outputs":[],"source":["\"\"\"\n","**Задание 7 (3 балла): Реализация модели BERT из библиотеки transformers**\n","\n","**Цель:** Ваша задача - реализовать модель BERT с использованием библиотеки transformers на наборе данных 20newsgroups.\n","Вывести на печать метрики модели на тестовом наборе test_data с помощью classification_report\n","\"\"\"\n","\n","# Загрузка предварительно обученного BERT\n","# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","# Импорт необходимых библиотек\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import pandas as pd\n","from sklearn.metrics import accuracy_score\n","from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n","from transformers import BertTokenizerFast, BertForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n","import random\n","# Загрузка датасета \"20 Newsgroups\"\n","from sklearn.datasets import fetch_20newsgroups\n","def read_20newsgroups(test_size=0.2):\n","\n","    dataset = fetch_20newsgroups(subset=\"all\", shuffle=True, remove=(\"headers\", \"footers\", \"quotes\"))\n","    documents = dataset.data\n","    labels = dataset.target\n","\n","    return train_test_split(documents, labels, test_size=test_size), dataset.target_names\n","\n","\n","(train_texts, valid_texts, train_labels, valid_labels), target_names = read_20newsgroups()"]},{"cell_type":"code","source":["model_name = \"bert-base-uncased\"\n","max_length = 512"],"metadata":{"id":"vrdUZa1T8epf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"],"metadata":{"id":"_TzQYNjz8wxs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n","valid_encodings = tokenizer(valid_texts, truncation=True, padding=True, max_length=max_length)"],"metadata":{"id":"ugJskSyY9Nnh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NewsGroupsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor([self.labels[idx]])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"metadata":{"id":"B-UzpUZV9RXL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = NewsGroupsDataset(train_encodings, train_labels)\n","valid_dataset = NewsGroupsDataset(valid_encodings, valid_labels)"],"metadata":{"id":"o3MMPb8a9T1-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","torch.cuda.empty_cache()\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z6leBWMC5odj","outputId":"23d45a59-c955-4477-94ce-2b03b26b9805"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n","Mon Oct 30 04:11:45 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8    12W /  70W |      3MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names)).to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5mkxNb3Z9X0U","outputId":"dada6cd0-d30b-464e-f2dc-4af7036fedc0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    acc = accuracy_score(labels, preds)\n","    print(classification_report(labels, preds))\n","    return {\n","        'accuracy': acc,\n","    }"],"metadata":{"id":"vGdy44nt9gQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=2,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    load_best_model_at_end=True,\n","    logging_steps=400,\n","    save_steps=400,\n","    evaluation_strategy=\"steps\",\n",")"],"metadata":{"id":"3cR18SEh9gLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"_qYDzKFl9gEy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lbQoswpaAA7b","outputId":"d32a1e46-0e11-4101-cc14-8101d3f4c3c2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1886' max='1886' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1886/1886 55:35, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>400</td>\n","      <td>0.959600</td>\n","      <td>1.094606</td>\n","      <td>0.676923</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.045100</td>\n","      <td>0.992490</td>\n","      <td>0.694430</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.732100</td>\n","      <td>0.934562</td>\n","      <td>0.727851</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.617600</td>\n","      <td>0.881277</td>\n","      <td>0.738992</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.40      0.39      0.40       151\n","           1       0.75      0.57      0.65       202\n","           2       0.40      0.73      0.51       195\n","           3       0.50      0.57      0.53       183\n","           4       0.70      0.56      0.62       205\n","           5       0.75      0.81      0.78       215\n","           6       0.76      0.71      0.73       193\n","           7       0.84      0.69      0.76       196\n","           8       0.75      0.70      0.72       168\n","           9       0.87      0.88      0.88       211\n","          10       0.91      0.82      0.86       198\n","          11       0.77      0.72      0.74       201\n","          12       0.61      0.61      0.61       202\n","          13       0.82      0.84      0.83       194\n","          14       0.83      0.77      0.80       189\n","          15       0.59      0.88      0.71       202\n","          16       0.78      0.52      0.63       188\n","          17       0.84      0.75      0.79       182\n","          18       0.45      0.70      0.54       159\n","          19       0.20      0.01      0.03       136\n","\n","    accuracy                           0.68      3770\n","   macro avg       0.68      0.66      0.66      3770\n","weighted avg       0.69      0.68      0.67      3770\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.47      0.63      0.54       151\n","           1       0.71      0.73      0.72       202\n","           2       0.76      0.50      0.60       195\n","           3       0.49      0.68      0.57       183\n","           4       0.84      0.52      0.64       205\n","           5       0.87      0.80      0.83       215\n","           6       0.91      0.56      0.69       193\n","           7       0.80      0.69      0.75       196\n","           8       0.45      0.83      0.58       168\n","           9       0.82      0.89      0.85       211\n","          10       0.98      0.86      0.92       198\n","          11       0.54      0.71      0.61       201\n","          12       0.56      0.72      0.63       202\n","          13       0.89      0.81      0.85       194\n","          14       0.81      0.80      0.81       189\n","          15       0.69      0.81      0.74       202\n","          16       0.64      0.79      0.70       188\n","          17       0.85      0.79      0.82       182\n","          18       0.70      0.52      0.59       159\n","          19       0.25      0.01      0.01       136\n","\n","    accuracy                           0.69      3770\n","   macro avg       0.70      0.68      0.67      3770\n","weighted avg       0.71      0.69      0.69      3770\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.44      0.53       151\n","           1       0.83      0.62      0.71       202\n","           2       0.61      0.69      0.65       195\n","           3       0.56      0.73      0.63       183\n","           4       0.75      0.75      0.75       205\n","           5       0.90      0.80      0.85       215\n","           6       0.86      0.73      0.79       193\n","           7       0.80      0.74      0.77       196\n","           8       0.61      0.77      0.68       168\n","           9       0.96      0.85      0.90       211\n","          10       0.93      0.88      0.90       198\n","          11       0.88      0.74      0.80       201\n","          12       0.67      0.68      0.67       202\n","          13       0.91      0.85      0.88       194\n","          14       0.69      0.81      0.74       189\n","          15       0.50      0.83      0.63       202\n","          16       0.65      0.82      0.73       188\n","          17       0.82      0.83      0.83       182\n","          18       0.75      0.54      0.63       159\n","          19       0.34      0.19      0.24       136\n","\n","    accuracy                           0.73      3770\n","   macro avg       0.73      0.71      0.72      3770\n","weighted avg       0.74      0.73      0.73      3770\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.63      0.56       151\n","           1       0.78      0.68      0.73       202\n","           2       0.69      0.67      0.68       195\n","           3       0.64      0.64      0.64       183\n","           4       0.82      0.74      0.78       205\n","           5       0.91      0.82      0.86       215\n","           6       0.83      0.78      0.80       193\n","           7       0.84      0.69      0.76       196\n","           8       0.61      0.79      0.69       168\n","           9       0.93      0.86      0.89       211\n","          10       0.98      0.85      0.91       198\n","          11       0.77      0.79      0.78       201\n","          12       0.62      0.76      0.68       202\n","          13       0.84      0.87      0.86       194\n","          14       0.55      0.86      0.67       189\n","          15       0.73      0.81      0.77       202\n","          16       0.73      0.73      0.73       188\n","          17       0.89      0.81      0.85       182\n","          18       0.62      0.62      0.62       159\n","          19       0.47      0.14      0.22       136\n","\n","    accuracy                           0.74      3770\n","   macro avg       0.74      0.73      0.72      3770\n","weighted avg       0.75      0.74      0.74      3770\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1886, training_loss=0.795119640556651, metrics={'train_runtime': 3336.8111, 'train_samples_per_second': 9.036, 'train_steps_per_second': 0.565, 'total_flos': 7934606683373568.0, 'train_loss': 0.795119640556651, 'epoch': 2.0})"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["trainer.evaluate()\n","# КОНЕЦ ВАШЕГО РЕШЕНИЯ"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":639},"id":"f8nq_pPhAAzO","outputId":"32bf7318-5b07-4797-8d5c-313e3ae9eedb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='236' max='236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [236/236 02:09]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.50      0.63      0.56       151\n","           1       0.78      0.68      0.73       202\n","           2       0.69      0.67      0.68       195\n","           3       0.64      0.64      0.64       183\n","           4       0.82      0.74      0.78       205\n","           5       0.91      0.82      0.86       215\n","           6       0.83      0.78      0.80       193\n","           7       0.84      0.69      0.76       196\n","           8       0.61      0.79      0.69       168\n","           9       0.93      0.86      0.89       211\n","          10       0.98      0.85      0.91       198\n","          11       0.77      0.79      0.78       201\n","          12       0.62      0.76      0.68       202\n","          13       0.84      0.87      0.86       194\n","          14       0.55      0.86      0.67       189\n","          15       0.73      0.81      0.77       202\n","          16       0.73      0.73      0.73       188\n","          17       0.89      0.81      0.85       182\n","          18       0.62      0.62      0.62       159\n","          19       0.47      0.14      0.22       136\n","\n","    accuracy                           0.74      3770\n","   macro avg       0.74      0.73      0.72      3770\n","weighted avg       0.75      0.74      0.74      3770\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.8812772035598755,\n"," 'eval_accuracy': 0.7389920424403184,\n"," 'eval_runtime': 129.7095,\n"," 'eval_samples_per_second': 29.065,\n"," 'eval_steps_per_second': 1.819,\n"," 'epoch': 2.0}"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"7794d2291628850022278c8953d59de9","grade":true,"grade_id":"cell-bb2981f26e950850","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"0Zg_p236bfgk","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["2c73a9d234b244ccb0c4b6d8ae7514ab","b12c2aa974ee4207871baa17b3a87167","7302ebf80d3e4306840b6b2bce17698e","e2a4801197624e3394040cd13d0725a7","5b87950fe6054dfbb622476292246a10","7341f0d3a69d4b18b4c22ff53b99ea30","5a27f9c1219a4425870ce546469996f2","6c42ee1f237d4e699987e38dc010200f","68083408f9b741e49b27ac4acd3d0955","62ada8eb899444fd9f9c41e105c84875","3c357d7bfc9148d1812c6933e6d7aa0e","a237cfa307b94ebb8ee196e094af1045","1c27ff6c851a42bca7e284a86319d444","a0f84a51346c42f4908f51c2948c212e","f99b78811c0f4d7da1d7023d666d444a","9c634cae40854aa3bb306e2d34c982aa","2bfe1fccea38456f8bb426ade80faf08","514d56ca3cb549d5ac5721b0282a355b","2597346f84fa4cf8a6f3b239826609ad","3024b06bdec7497ca6c5aac5b8b712b9","0dc1224ba509424f9838bf398df9ff38","4c5a0de0273141ae93844b6e87f3f4d9","ac1731d0e4534f17a2b71fa98d0e3d5d","63ee29598a5e48cb9cdea31840dfeb30","5154d182e91d4295ab3caf86f8b66be3","03e80e20439f4350bd2db76747ed019e","7e4b936dda8841f6bd11d786bae43b39","7dcf0da9a42e4fa6bc10aaf90517fe3f","51b1408bd84642719e8e0db040b370a4","3d2c02ebb50a45d9b4631fb099f207e2","2ce05bf67f1a49348b7741988bc0518e","2a9c23f840a04f14856b3f32ab9c8205","f8043be8bb0f41eca7eeb8443a4e47c5","4610d88ae5444088b00cc19c28a23d4b","7b55e40b1ddb4796a0081663dcb02cc1","fd0db2b6f628460f89a1a1384dab39e5","25f58cace1e6455e87aa351b088f8847","b7030fcb85c6419d9d17fd953dd75c26","15ce561dc2214bbab8f5465a1b9faab6","291081a08df74e0f985d2977e6500b08","020bcbc8036846109df551c6ebaf4a06","0dd7b1ee64ed49a2b051f1fea679f9c6","3dba9afd93f24d1fac1c674a2afed7c3","df962e164a0744949c4b314f38aa9329"]},"outputId":"47b745d7-d900-4e08-9c48-22b6807f7af3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c73a9d234b244ccb0c4b6d8ae7514ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a237cfa307b94ebb8ee196e094af1045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac1731d0e4534f17a2b71fa98d0e3d5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4610d88ae5444088b00cc19c28a23d4b"}},"metadata":{}}],"source":["\"\"\"\n","**Задание 8 (3 балла): Реализация модели BART из библиотеки transformers**\n","\n","**Цель:** Ваша задача - реализовать модель BART с использованием библиотеки transformers на наборе данных 20newsgroups.\n","Вывести на печать метрики модели на тестовом наборе test_data с помощью classification_report\n","\"\"\"\n","from transformers import BartTokenizerFast, BartForSequenceClassification\n","# Загрузка предварительно обученного BART\n","# НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","model_name = \"facebook/bart-base\"\n","max_length = 512\n","tokenizer = BartTokenizerFast.from_pretrained(model_name, do_lower_case=True)"]},{"cell_type":"code","source":["train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n","valid_encodings = tokenizer(valid_texts, truncation=True, padding=True, max_length=max_length)"],"metadata":{"id":"QKPIpcg5oeF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = NewsGroupsDataset(train_encodings, train_labels)\n","valid_dataset = NewsGroupsDataset(valid_encodings, valid_labels)"],"metadata":{"id":"Za_R5CbNojti"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BartForSequenceClassification.from_pretrained(model_name, num_labels=len(target_names)).to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["614ae3dd2d2242298a33073d2800f4c9","aa0c941cd9b34663bfcaa15cd15086e6","d5c8585bff6741fdbfa525c27bdd6c2a","7741797013e0435f8bc4c5fd7cb69700","af244c5340f44a0db67fe58f1239da5a","aad5b7f44922491db401309789d67ed4","a11ea564fa944070b8326e6fa61ef542","431c09f76f0440858d92c1a556a0941a","ccb928a8dcd74d5baf3044dd4c5b4be3","45014c0e9a864b3991fb7e9dd7b444ec","aba188a1c21b47b680214386702000a8"]},"id":"LUYlTwqUom-h","outputId":"8dd16569-c48d-49f8-fc86-15e47b969cb2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"614ae3dd2d2242298a33073d2800f4c9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.out_proj.weight', 'classification_head.out_proj.bias', 'classification_head.dense.weight', 'classification_head.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions[0].argmax(-1)\n","    acc = accuracy_score(labels, preds)\n","    print(classification_report(labels, preds))\n","    return {\n","        'accuracy': acc,\n","    }"],"metadata":{"id":"pIcitMpc4LSB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=2,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=4,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    load_best_model_at_end=True,\n","    logging_steps=400,\n","    save_steps=400,\n","    evaluation_strategy=\"steps\",\n",")"],"metadata":{"id":"OXYK863-pYgH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"Gejj3D80pam7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"O3PBQa2LovO-","outputId":"88cc3223-40e8-49da-ba6e-0c9072d1614f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3770' max='3770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3770/3770 1:33:44, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>400</td>\n","      <td>2.176900</td>\n","      <td>1.220463</td>\n","      <td>0.623607</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.241100</td>\n","      <td>1.105368</td>\n","      <td>0.669496</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>1.144600</td>\n","      <td>1.046774</td>\n","      <td>0.697878</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>1.068100</td>\n","      <td>0.965019</td>\n","      <td>0.708488</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.924000</td>\n","      <td>0.958349</td>\n","      <td>0.711671</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.749400</td>\n","      <td>0.932397</td>\n","      <td>0.732891</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.764900</td>\n","      <td>0.855966</td>\n","      <td>0.747215</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.709600</td>\n","      <td>0.861367</td>\n","      <td>0.748541</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.663900</td>\n","      <td>0.852308</td>\n","      <td>0.754111</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.48      0.52      0.50       149\n","           1       0.55      0.61      0.58       188\n","           2       0.45      0.42      0.44       173\n","           3       0.64      0.04      0.07       190\n","           4       0.30      0.77      0.43       195\n","           5       0.74      0.70      0.72       192\n","           6       0.72      0.77      0.74       195\n","           7       0.45      0.81      0.58       172\n","           8       0.82      0.60      0.69       203\n","           9       0.95      0.80      0.87       200\n","          10       0.91      0.90      0.91       219\n","          11       0.66      0.70      0.68       199\n","          12       0.48      0.33      0.39       208\n","          13       0.95      0.67      0.78       209\n","          14       0.90      0.69      0.78       198\n","          15       0.75      0.76      0.75       211\n","          16       0.65      0.65      0.65       198\n","          17       0.85      0.78      0.82       187\n","          18       0.41      0.62      0.49       154\n","          19       0.38      0.07      0.12       130\n","\n","    accuracy                           0.62      3770\n","   macro avg       0.65      0.61      0.60      3770\n","weighted avg       0.67      0.62      0.62      3770\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.24      0.33       149\n","           1       0.67      0.59      0.63       188\n","           2       0.68      0.54      0.60       173\n","           3       0.59      0.54      0.56       190\n","           4       0.67      0.61      0.63       195\n","           5       0.65      0.85      0.73       192\n","           6       0.79      0.78      0.79       195\n","           7       0.79      0.66      0.72       172\n","           8       0.92      0.61      0.73       203\n","           9       0.92      0.85      0.89       200\n","          10       0.93      0.89      0.91       219\n","          11       0.68      0.74      0.71       199\n","          12       0.58      0.53      0.56       208\n","          13       0.56      0.79      0.65       209\n","          14       0.94      0.61      0.74       198\n","          15       0.68      0.85      0.75       211\n","          16       0.58      0.72      0.64       198\n","          17       0.79      0.82      0.81       187\n","          18       0.35      0.68      0.46       154\n","          19       0.25      0.18      0.21       130\n","\n","    accuracy                           0.67      3770\n","   macro avg       0.68      0.65      0.65      3770\n","weighted avg       0.69      0.67      0.67      3770\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.42      0.45       149\n","           1       0.74      0.56      0.64       188\n","           2       0.68      0.59      0.63       173\n","           3       0.51      0.77      0.62       190\n","           4       0.74      0.57      0.65       195\n","           5       0.76      0.82      0.79       192\n","           6       0.82      0.75      0.78       195\n","           7       0.77      0.67      0.72       172\n","           8       0.84      0.66      0.74       203\n","           9       0.71      0.91      0.80       200\n","          10       0.94      0.90      0.92       219\n","          11       0.82      0.75      0.78       199\n","          12       0.69      0.52      0.60       208\n","          13       0.81      0.86      0.83       209\n","          14       0.78      0.78      0.78       198\n","          15       0.59      0.90      0.72       211\n","          16       0.58      0.63      0.60       198\n","          17       0.64      0.84      0.73       187\n","          18       0.50      0.69      0.58       154\n","          19       0.00      0.00      0.00       130\n","\n","    accuracy                           0.70      3770\n","   macro avg       0.67      0.68      0.67      3770\n","weighted avg       0.69      0.70      0.69      3770\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.40      0.52       149\n","           1       0.65      0.72      0.69       188\n","           2       0.67      0.67      0.67       173\n","           3       0.68      0.65      0.66       190\n","           4       0.73      0.69      0.71       195\n","           5       0.87      0.73      0.80       192\n","           6       0.79      0.84      0.82       195\n","           7       0.43      0.86      0.57       172\n","           8       0.84      0.66      0.74       203\n","           9       0.85      0.86      0.85       200\n","          10       0.95      0.87      0.91       219\n","          11       0.90      0.70      0.79       199\n","          12       0.68      0.55      0.61       208\n","          13       0.82      0.86      0.84       209\n","          14       0.61      0.84      0.71       198\n","          15       0.74      0.72      0.73       211\n","          16       0.73      0.63      0.67       198\n","          17       0.70      0.86      0.77       187\n","          18       0.60      0.60      0.60       154\n","          19       0.26      0.18      0.21       130\n","\n","    accuracy                           0.71      3770\n","   macro avg       0.71      0.69      0.69      3770\n","weighted avg       0.72      0.71      0.71      3770\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.63      0.47       149\n","           1       0.69      0.70      0.69       188\n","           2       0.56      0.74      0.64       173\n","           3       0.83      0.50      0.62       190\n","           4       0.74      0.67      0.70       195\n","           5       0.79      0.84      0.81       192\n","           6       0.86      0.79      0.83       195\n","           7       0.52      0.81      0.63       172\n","           8       0.71      0.76      0.74       203\n","           9       0.96      0.86      0.91       200\n","          10       0.94      0.94      0.94       219\n","          11       0.74      0.75      0.75       199\n","          12       0.71      0.50      0.58       208\n","          13       0.93      0.83      0.87       209\n","          14       0.68      0.83      0.75       198\n","          15       0.84      0.60      0.70       211\n","          16       0.72      0.67      0.69       198\n","          17       0.80      0.86      0.82       187\n","          18       0.47      0.68      0.56       154\n","          19       0.25      0.03      0.05       130\n","\n","    accuracy                           0.71      3770\n","   macro avg       0.71      0.70      0.69      3770\n","weighted avg       0.73      0.71      0.71      3770\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.54      0.55      0.54       149\n","           1       0.68      0.65      0.67       188\n","           2       0.67      0.64      0.66       173\n","           3       0.62      0.69      0.65       190\n","           4       0.86      0.68      0.76       195\n","           5       0.76      0.83      0.79       192\n","           6       0.82      0.83      0.82       195\n","           7       0.72      0.74      0.73       172\n","           8       0.80      0.74      0.77       203\n","           9       0.68      0.89      0.77       200\n","          10       0.93      0.92      0.93       219\n","          11       0.81      0.76      0.78       199\n","          12       0.67      0.60      0.63       208\n","          13       0.92      0.83      0.87       209\n","          14       0.82      0.79      0.81       198\n","          15       0.70      0.87      0.78       211\n","          16       0.65      0.75      0.70       198\n","          17       0.68      0.86      0.76       187\n","          18       0.59      0.65      0.62       154\n","          19       0.67      0.05      0.09       130\n","\n","    accuracy                           0.73      3770\n","   macro avg       0.73      0.72      0.71      3770\n","weighted avg       0.74      0.73      0.72      3770\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.50      0.54       149\n","           1       0.63      0.66      0.64       188\n","           2       0.69      0.65      0.67       173\n","           3       0.69      0.70      0.70       190\n","           4       0.79      0.72      0.75       195\n","           5       0.79      0.85      0.82       192\n","           6       0.83      0.83      0.83       195\n","           7       0.51      0.83      0.64       172\n","           8       0.63      0.82      0.71       203\n","           9       0.89      0.88      0.89       200\n","          10       0.97      0.90      0.93       219\n","          11       0.83      0.78      0.81       199\n","          12       0.73      0.63      0.68       208\n","          13       0.86      0.89      0.88       209\n","          14       0.87      0.81      0.84       198\n","          15       0.78      0.80      0.79       211\n","          16       0.69      0.68      0.69       198\n","          17       0.89      0.82      0.85       187\n","          18       0.77      0.62      0.69       154\n","          19       0.40      0.31      0.35       130\n","\n","    accuracy                           0.75      3770\n","   macro avg       0.74      0.73      0.73      3770\n","weighted avg       0.75      0.75      0.75      3770\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.52      0.62      0.57       149\n","           1       0.70      0.69      0.70       188\n","           2       0.66      0.68      0.67       173\n","           3       0.63      0.75      0.68       190\n","           4       0.80      0.72      0.76       195\n","           5       0.84      0.82      0.83       192\n","           6       0.78      0.85      0.81       195\n","           7       0.82      0.72      0.77       172\n","           8       0.71      0.82      0.76       203\n","           9       0.62      0.90      0.74       200\n","          10       0.91      0.92      0.91       219\n","          11       0.83      0.78      0.80       199\n","          12       0.77      0.59      0.67       208\n","          13       0.86      0.88      0.87       209\n","          14       0.88      0.80      0.84       198\n","          15       0.77      0.82      0.79       211\n","          16       0.70      0.69      0.69       198\n","          17       0.77      0.87      0.81       187\n","          18       0.77      0.60      0.68       154\n","          19       0.57      0.15      0.24       130\n","\n","    accuracy                           0.75      3770\n","   macro avg       0.74      0.73      0.73      3770\n","weighted avg       0.75      0.75      0.74      3770\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.56      0.58       149\n","           1       0.71      0.70      0.70       188\n","           2       0.66      0.71      0.68       173\n","           3       0.70      0.71      0.70       190\n","           4       0.81      0.71      0.76       195\n","           5       0.83      0.83      0.83       192\n","           6       0.79      0.86      0.82       195\n","           7       0.58      0.81      0.67       172\n","           8       0.76      0.81      0.78       203\n","           9       0.78      0.89      0.83       200\n","          10       0.92      0.93      0.92       219\n","          11       0.83      0.79      0.81       199\n","          12       0.77      0.60      0.67       208\n","          13       0.87      0.89      0.88       209\n","          14       0.80      0.81      0.81       198\n","          15       0.73      0.85      0.78       211\n","          16       0.70      0.71      0.71       198\n","          17       0.79      0.87      0.83       187\n","          18       0.72      0.61      0.66       154\n","          19       0.46      0.13      0.20       130\n","\n","    accuracy                           0.75      3770\n","   macro avg       0.74      0.74      0.73      3770\n","weighted avg       0.75      0.75      0.75      3770\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3770, training_loss=1.032909423666228, metrics={'train_runtime': 5628.7399, 'train_samples_per_second': 5.357, 'train_steps_per_second': 0.67, 'total_flos': 9248516178935808.0, 'train_loss': 1.032909423666228, 'epoch': 2.0})"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":610},"id":"GqgkTNUbFqh4","outputId":"b2e7e67f-96fb-4c5d-abcc-06fd2a6c6b0a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='943' max='943' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [943/943 03:18]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.56      0.58       149\n","           1       0.71      0.70      0.70       188\n","           2       0.66      0.71      0.68       173\n","           3       0.70      0.71      0.70       190\n","           4       0.81      0.71      0.76       195\n","           5       0.83      0.83      0.83       192\n","           6       0.79      0.86      0.82       195\n","           7       0.58      0.81      0.67       172\n","           8       0.76      0.81      0.78       203\n","           9       0.78      0.89      0.83       200\n","          10       0.92      0.93      0.92       219\n","          11       0.83      0.79      0.81       199\n","          12       0.77      0.60      0.67       208\n","          13       0.87      0.89      0.88       209\n","          14       0.80      0.81      0.81       198\n","          15       0.73      0.85      0.78       211\n","          16       0.70      0.71      0.71       198\n","          17       0.79      0.87      0.83       187\n","          18       0.72      0.61      0.66       154\n","          19       0.46      0.13      0.20       130\n","\n","    accuracy                           0.75      3770\n","   macro avg       0.74      0.74      0.73      3770\n","weighted avg       0.75      0.75      0.75      3770\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.8523082733154297,\n"," 'eval_accuracy': 0.7541114058355438,\n"," 'eval_runtime': 202.9059,\n"," 'eval_samples_per_second': 18.58,\n"," 'eval_steps_per_second': 4.647,\n"," 'epoch': 2.0}"]},"metadata":{},"execution_count":21}]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2c73a9d234b244ccb0c4b6d8ae7514ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b12c2aa974ee4207871baa17b3a87167","IPY_MODEL_7302ebf80d3e4306840b6b2bce17698e","IPY_MODEL_e2a4801197624e3394040cd13d0725a7"],"layout":"IPY_MODEL_5b87950fe6054dfbb622476292246a10"}},"b12c2aa974ee4207871baa17b3a87167":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7341f0d3a69d4b18b4c22ff53b99ea30","placeholder":"​","style":"IPY_MODEL_5a27f9c1219a4425870ce546469996f2","value":"Downloading (…)olve/main/vocab.json: 100%"}},"7302ebf80d3e4306840b6b2bce17698e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c42ee1f237d4e699987e38dc010200f","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68083408f9b741e49b27ac4acd3d0955","value":898823}},"e2a4801197624e3394040cd13d0725a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62ada8eb899444fd9f9c41e105c84875","placeholder":"​","style":"IPY_MODEL_3c357d7bfc9148d1812c6933e6d7aa0e","value":" 899k/899k [00:00&lt;00:00, 3.75MB/s]"}},"5b87950fe6054dfbb622476292246a10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7341f0d3a69d4b18b4c22ff53b99ea30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a27f9c1219a4425870ce546469996f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c42ee1f237d4e699987e38dc010200f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68083408f9b741e49b27ac4acd3d0955":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62ada8eb899444fd9f9c41e105c84875":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c357d7bfc9148d1812c6933e6d7aa0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a237cfa307b94ebb8ee196e094af1045":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c27ff6c851a42bca7e284a86319d444","IPY_MODEL_a0f84a51346c42f4908f51c2948c212e","IPY_MODEL_f99b78811c0f4d7da1d7023d666d444a"],"layout":"IPY_MODEL_9c634cae40854aa3bb306e2d34c982aa"}},"1c27ff6c851a42bca7e284a86319d444":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bfe1fccea38456f8bb426ade80faf08","placeholder":"​","style":"IPY_MODEL_514d56ca3cb549d5ac5721b0282a355b","value":"Downloading (…)olve/main/merges.txt: 100%"}},"a0f84a51346c42f4908f51c2948c212e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2597346f84fa4cf8a6f3b239826609ad","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3024b06bdec7497ca6c5aac5b8b712b9","value":456318}},"f99b78811c0f4d7da1d7023d666d444a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dc1224ba509424f9838bf398df9ff38","placeholder":"​","style":"IPY_MODEL_4c5a0de0273141ae93844b6e87f3f4d9","value":" 456k/456k [00:00&lt;00:00, 8.21MB/s]"}},"9c634cae40854aa3bb306e2d34c982aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bfe1fccea38456f8bb426ade80faf08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"514d56ca3cb549d5ac5721b0282a355b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2597346f84fa4cf8a6f3b239826609ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3024b06bdec7497ca6c5aac5b8b712b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0dc1224ba509424f9838bf398df9ff38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c5a0de0273141ae93844b6e87f3f4d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac1731d0e4534f17a2b71fa98d0e3d5d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63ee29598a5e48cb9cdea31840dfeb30","IPY_MODEL_5154d182e91d4295ab3caf86f8b66be3","IPY_MODEL_03e80e20439f4350bd2db76747ed019e"],"layout":"IPY_MODEL_7e4b936dda8841f6bd11d786bae43b39"}},"63ee29598a5e48cb9cdea31840dfeb30":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dcf0da9a42e4fa6bc10aaf90517fe3f","placeholder":"​","style":"IPY_MODEL_51b1408bd84642719e8e0db040b370a4","value":"Downloading (…)/main/tokenizer.json: 100%"}},"5154d182e91d4295ab3caf86f8b66be3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d2c02ebb50a45d9b4631fb099f207e2","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ce05bf67f1a49348b7741988bc0518e","value":1355863}},"03e80e20439f4350bd2db76747ed019e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a9c23f840a04f14856b3f32ab9c8205","placeholder":"​","style":"IPY_MODEL_f8043be8bb0f41eca7eeb8443a4e47c5","value":" 1.36M/1.36M [00:00&lt;00:00, 10.5MB/s]"}},"7e4b936dda8841f6bd11d786bae43b39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dcf0da9a42e4fa6bc10aaf90517fe3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51b1408bd84642719e8e0db040b370a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d2c02ebb50a45d9b4631fb099f207e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ce05bf67f1a49348b7741988bc0518e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a9c23f840a04f14856b3f32ab9c8205":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8043be8bb0f41eca7eeb8443a4e47c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4610d88ae5444088b00cc19c28a23d4b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b55e40b1ddb4796a0081663dcb02cc1","IPY_MODEL_fd0db2b6f628460f89a1a1384dab39e5","IPY_MODEL_25f58cace1e6455e87aa351b088f8847"],"layout":"IPY_MODEL_b7030fcb85c6419d9d17fd953dd75c26"}},"7b55e40b1ddb4796a0081663dcb02cc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15ce561dc2214bbab8f5465a1b9faab6","placeholder":"​","style":"IPY_MODEL_291081a08df74e0f985d2977e6500b08","value":"Downloading (…)lve/main/config.json: 100%"}},"fd0db2b6f628460f89a1a1384dab39e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_020bcbc8036846109df551c6ebaf4a06","max":1716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0dd7b1ee64ed49a2b051f1fea679f9c6","value":1716}},"25f58cace1e6455e87aa351b088f8847":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3dba9afd93f24d1fac1c674a2afed7c3","placeholder":"​","style":"IPY_MODEL_df962e164a0744949c4b314f38aa9329","value":" 1.72k/1.72k [00:00&lt;00:00, 107kB/s]"}},"b7030fcb85c6419d9d17fd953dd75c26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15ce561dc2214bbab8f5465a1b9faab6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"291081a08df74e0f985d2977e6500b08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"020bcbc8036846109df551c6ebaf4a06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dd7b1ee64ed49a2b051f1fea679f9c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3dba9afd93f24d1fac1c674a2afed7c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df962e164a0744949c4b314f38aa9329":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"614ae3dd2d2242298a33073d2800f4c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa0c941cd9b34663bfcaa15cd15086e6","IPY_MODEL_d5c8585bff6741fdbfa525c27bdd6c2a","IPY_MODEL_7741797013e0435f8bc4c5fd7cb69700"],"layout":"IPY_MODEL_af244c5340f44a0db67fe58f1239da5a"}},"aa0c941cd9b34663bfcaa15cd15086e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aad5b7f44922491db401309789d67ed4","placeholder":"​","style":"IPY_MODEL_a11ea564fa944070b8326e6fa61ef542","value":"Downloading model.safetensors: 100%"}},"d5c8585bff6741fdbfa525c27bdd6c2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_431c09f76f0440858d92c1a556a0941a","max":557709915,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccb928a8dcd74d5baf3044dd4c5b4be3","value":557709915}},"7741797013e0435f8bc4c5fd7cb69700":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45014c0e9a864b3991fb7e9dd7b444ec","placeholder":"​","style":"IPY_MODEL_aba188a1c21b47b680214386702000a8","value":" 558M/558M [00:07&lt;00:00, 66.5MB/s]"}},"af244c5340f44a0db67fe58f1239da5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aad5b7f44922491db401309789d67ed4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a11ea564fa944070b8326e6fa61ef542":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"431c09f76f0440858d92c1a556a0941a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccb928a8dcd74d5baf3044dd4c5b4be3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45014c0e9a864b3991fb7e9dd7b444ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aba188a1c21b47b680214386702000a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}