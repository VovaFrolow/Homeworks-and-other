{"cells":[{"cell_type":"markdown","id":"1212517c","metadata":{"id":"1212517c"},"source":["# **Важно!**\n","\n","Домашнее задание состоит из нескольких задач, которые вам нужно решить.\n","*   Баллы выставляются по принципу выполнено/невыполнено.\n","*   За каждую выполненую задачу вы получаете баллы (количество баллов за задание указано в скобках).\n","\n","**Инструкция выполнения:** Выполните задания в этом же ноутбуке (места под решения **КАЖДОЙ** задачи обозначены как **#НАЧАЛО ВАШЕГО РЕШЕНИЯ** и **#КОНЕЦ ВАШЕГО РЕШЕНИЯ**)\n","\n","**Как отправить задание на проверку:** Вам необходимо сохранить ваше решение в данном блокноте и отправить итоговый **файл .IPYNB** на учебной платформе в **стандартную форму сдачи домашнего задания.**\n","\n","**Срок проверки преподавателем:** домашнее задание проверяется **в течение 3 дней после дедлайна сдачи** с предоставлением обратной связи\n","\n","# **Прежде чем проверять задания:**\n","\n","1. Перезапустите **ядро (restart the kernel)**: в меню, выбрать **Ядро (Kernel)**\n","→ **Перезапустить (Restart)**\n","2. Затем **Выполнить** **все ячейки (run all cells)**: в меню, выбрать **Ячейка (Cell)**\n","→ **Запустить все (Run All)**.\n","\n","После ячеек с заданием следуют ячейки с проверкой **с помощью assert.**\n","\n","Если в коде есть ошибки, assert выведет уведомление об ошибке.\n","\n","Если в коде нет ошибок, assert отработает без вывода дополнительной информации."]},{"cell_type":"markdown","id":"c07ea4f4","metadata":{"id":"c07ea4f4"},"source":["---"]},{"cell_type":"code","execution_count":null,"id":"27450ccb-9f7b-4873-88ac-d6163cf59888","metadata":{"id":"27450ccb-9f7b-4873-88ac-d6163cf59888"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","id":"9ff1d07f-d8cc-4eb4-ba1f-122a6594bde8","metadata":{"id":"9ff1d07f-d8cc-4eb4-ba1f-122a6594bde8"},"source":["# Упрощенная модель GPT"]},{"cell_type":"markdown","id":"db95f662-dd66-44fa-8f10-e8d847254d3e","metadata":{"id":"db95f662-dd66-44fa-8f10-e8d847254d3e"},"source":["### Конфигурация модели"]},{"cell_type":"code","execution_count":null,"id":"7ea72c95-25a2-44a5-b865-9704847057c7","metadata":{"id":"7ea72c95-25a2-44a5-b865-9704847057c7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eea58b7b-5598-421a-8528-6a943b912c96"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x794178923f30>"]},"metadata":{},"execution_count":2}],"source":["config = {\n","  \"n_ctx\": 32,  # Максимальная длина контекста (context).\n","  \"n_embd\": 64,  # Размерность встраивания (embedding dimension).\n","  \"n_head\": 4,  # Количество внимательных голов (attention heads) в многоголовом внимании.\n","  \"n_layer\": 4,  # Количество слоев в модели.\n","  \"dropout\": 0.0,  # Дропаут  (dropout) для предотвращения переобучения.\n","  \"vocab_size\": None,  # Размер словаря модели.\n","  \"batch_size\": 16,  # Размер словаря модели.\n","  \"eval_interval\": 100,  # Шаг для вывода оценки модели.\n","  \"eval_iters\": 100,  # Шаг для вывода оценки модели.\n","  \"learning_rate\": 1e-3,  # Шаг обучения.\n","}\n","config[\"head_size\"]  = config[\"n_embd\"] // config[\"n_head\"]\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","torch.manual_seed(1)"]},{"cell_type":"markdown","id":"edd20444-4513-41b4-a627-4679531b6cf9","metadata":{"id":"edd20444-4513-41b4-a627-4679531b6cf9"},"source":["### Подготовка данных\n","\n","Процесс подготовки данных включает в себя следующие этапы:\n","\n","1. Сбор данных: Сначала необходимо собрать исходные данные, на которых будет обучаться модель GPT. Это может быть большой корпус текстов, содержащий разнообразные данные, в зависимости от вашей задачных: Данные обычно требуют предварительной обработки, включая очистку от мусорных символов, токенизацию (разбиение текста на токены, как слова или подстр тру и другие операции, зависящие от задач2.\n","\n","3. Токенизация: Модели GPT работают с токенами, поэтому текст должен быть преобразован в последовательность токенов. Вы можете использовать токенизаторы, предоставляемые библиотеками, такими как Hugging Face Transformers, для выполнения этой оп\n","   \n","3. Разделение данных: Данные обычно разделяются на тренировочную, валидационную и тестовую выборки для оценки и тестирования модели.ер43ии.\n","\n","4. Создание последовательностей: Данные обычно разбиваются на последовательности или \"окна\", чтобы модель могла изучать контекст. Это может потребовать создания окон разной длины, в зависимости от задачи. Создание целевых последовательностей (для обучения с учителем): Если вы обучаете модель с учителем, вам также потребуется создать целевые последовательности, которые модель будет пытаться пр ответ на запросы."]},{"cell_type":"markdown","id":"006c4303-5d01-41d0-8f46-e42e45aaf457","metadata":{"id":"006c4303-5d01-41d0-8f46-e42e45aaf457"},"source":["### 1. Сбор данных"]},{"cell_type":"code","execution_count":null,"id":"6787ca47-8c04-4d57-a3b0-698f3a4c2d2f","metadata":{"id":"6787ca47-8c04-4d57-a3b0-698f3a4c2d2f","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d5e6ef2-8ee1-4069-f440-d6e591285823"},"outputs":[{"output_type":"stream","name":"stdout","text":["length of dataset in characters:  1115394\n","First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You\n"]}],"source":["# with open('data/input.txt', 'r', encoding='utf-8') as f:\n","#    text = f.read()\n","with open('/content/input.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()\n","\n","print(\"length of dataset in characters: \", len(text))\n","\n","# let's look at the first 1000 characters\n","print(text[:100])"]},{"cell_type":"markdown","id":"fd2bd88a-1f44-4933-adc3-4a215b815bb9","metadata":{"id":"fd2bd88a-1f44-4933-adc3-4a215b815bb9"},"source":["### 2. Токенизация для упрощенной модели GPT"]},{"cell_type":"code","execution_count":null,"id":"e7739b4a-e959-4d47-9ae2-829c2853e9a1","metadata":{"id":"e7739b4a-e959-4d47-9ae2-829c2853e9a1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7366a487-0419-46e0-8a6e-5a5862bf7def"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","65\n"]}],"source":["# Токенизация для упрощенной модели GPT\n","chars = sorted(list(set(text)))\n","config[\"vocab_size\"] = len(chars)\n","print(''.join(chars))\n","print(config[\"vocab_size\"])"]},{"cell_type":"code","execution_count":null,"id":"cb054b8a-5b84-4ec1-b6a1-e49cef45692b","metadata":{"id":"cb054b8a-5b84-4ec1-b6a1-e49cef45692b"},"outputs":[],"source":["# create a mapping from characters to integers\n","stoi = { ch:i for i,ch in enumerate(chars) }\n","itos = { i:ch for i,ch in enumerate(chars) }\n","encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n","decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"]},{"cell_type":"code","execution_count":null,"id":"d0e6d412-d58a-48db-adcd-1804728e3824","metadata":{"id":"d0e6d412-d58a-48db-adcd-1804728e3824","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d30c47f6-1f65-415b-f9a4-884259cb4927"},"outputs":[{"output_type":"stream","name":"stdout","text":["[46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\n","hello world\n"]}],"source":["print(encode(\"hello world\"))\n","print(decode(encode(\"hello world\")))"]},{"cell_type":"markdown","id":"8a28e32e-d41f-48d7-a153-c2742a22c252","metadata":{"id":"8a28e32e-d41f-48d7-a153-c2742a22c252"},"source":["### 3. Разделение данных"]},{"cell_type":"code","execution_count":null,"id":"2d17d8c2-9e28-4bec-a793-11d2e552e453","metadata":{"id":"2d17d8c2-9e28-4bec-a793-11d2e552e453","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f2798e52-f514-4e91-987f-0904931cbf61"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n","         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n","        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n","         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n","        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"]}],"source":["# Train and test splits\n","\n","# put all data into a PyTorch tensor\n","data = torch.tensor(encode(text), dtype=torch.long)\n","\n","# creating train and test datasets\n","n = int(0.9*len(data)) # first 90% will be train, rest val\n","train_data = data[:n]\n","val_data = data[n:]\n","\n","print(train_data[:100])"]},{"cell_type":"markdown","id":"ee1ec91a-5e8a-4f9e-9a54-55002e8632f9","metadata":{"id":"ee1ec91a-5e8a-4f9e-9a54-55002e8632f9"},"source":["### 4. Создание последовательностей"]},{"cell_type":"code","execution_count":null,"id":"8499ecbf-951b-44a6-8b9a-c98b481157c3","metadata":{"id":"8499ecbf-951b-44a6-8b9a-c98b481157c3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0da1df5-e9e7-47c6-8690-dbdd02426b56"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1])"]},"metadata":{},"execution_count":8}],"source":["# printing a n_ctx of train data\n","n_ctx = config[\"n_ctx\"]\n","batch_size = config[\"batch_size\"]\n","train_data[:n_ctx +1]"]},{"cell_type":"code","execution_count":null,"id":"2973a040-30c5-4bfd-a958-c2e886e052a3","metadata":{"id":"2973a040-30c5-4bfd-a958-c2e886e052a3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"35034b1e-8141-478d-aaee-c6cfd0ed9e6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["when input is tensor([18]) the target: 47\n","when input is tensor([18, 47]) the target: 56\n","when input is tensor([18, 47, 56]) the target: 57\n","when input is tensor([18, 47, 56, 57]) the target: 58\n","when input is tensor([18, 47, 56, 57, 58]) the target: 1\n","when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n","when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58]) the target: 47\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47]) the target: 64\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64]) the target: 43\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43]) the target: 52\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52]) the target: 10\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10]) the target: 0\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0]) the target: 14\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14]) the target: 43\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43]) the target: 44\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44]) the target: 53\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53]) the target: 56\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56]) the target: 43\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43]) the target: 1\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1]) the target: 61\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61]) the target: 43\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43]) the target: 1\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1]) the target: 54\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54]) the target: 56\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56]) the target: 53\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53]) the target: 41\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41]) the target: 43\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43]) the target: 43\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43]) the target: 42\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42]) the target: 1\n"]}],"source":["# exploring test and train data\n","x = train_data[:n_ctx]\n","y = train_data[1:n_ctx+1]\n","for t in range(n_ctx):\n","    context = x[:t+1]\n","    target = y[t]\n","    print(f\"when input is {context} the target: {target}\")"]},{"cell_type":"code","execution_count":null,"id":"cfa70482-b63c-45f5-9306-de4063b1f205","metadata":{"id":"cfa70482-b63c-45f5-9306-de4063b1f205"},"outputs":[],"source":["# data loading\n","def get_batch(split):\n","    # generate a small batch of data of inputs x and targets y\n","    data = train_data if split == 'train' else val_data\n","    ix = torch.randint(len(data) - n_ctx, (batch_size,))\n","    x = torch.stack([data[i:i+n_ctx] for i in ix])\n","    y = torch.stack([data[i+1:i+n_ctx+1] for i in ix])\n","    x, y = x.to(device), y.to(device)\n","    return x, y"]},{"cell_type":"code","execution_count":null,"id":"a591e5b9-3963-4d58-a3b8-c12154a83aa2","metadata":{"id":"a591e5b9-3963-4d58-a3b8-c12154a83aa2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a33b109b-59aa-46c4-cbf7-35e37f1a3ca3"},"outputs":[{"output_type":"stream","name":"stdout","text":["inputs:\n","torch.Size([16, 32])\n","tensor([[39, 52, 42,  1, 52, 53, 61, 12,  1, 61, 46, 43, 56, 43,  1, 40, 43,  1,\n","         58, 46, 63,  1, 40, 56, 53, 58, 46, 43, 56, 57, 12,  0],\n","        [ 6,  1, 57, 43, 43, 49,  6,  1, 39, 52, 42,  1, 49, 52, 53, 61,  1, 46,\n","         53, 61,  1, 58, 46, 47, 57,  1, 44, 53, 59, 50,  1, 51],\n","        [50,  1, 56, 39, 47, 50,  1, 47, 52,  0, 46, 47, 57,  1, 56, 53, 54, 43,\n","          7, 58, 56, 47, 41, 49, 57,  8,  1, 21,  5, 50, 50,  1],\n","        [39, 52, 42,  1, 43, 52, 58, 56, 43, 39, 58,  1, 58, 46, 43, 51,  6,  0,\n","         18, 53, 56,  1, 51, 63,  1, 61, 53, 59, 52, 42, 57,  5],\n","        [20, 43, 56, 43,  1, 41, 53, 51, 43, 57,  1, 30, 53, 51, 43, 53,  6,  1,\n","         46, 43, 56, 43,  1, 41, 53, 51, 43, 57,  1, 30, 53, 51],\n","        [57, 58,  1, 58, 46, 53, 59,  1, 44, 43, 43, 50,  1, 58, 46, 63, 57, 43,\n","         50, 44,  1, 52, 53, 61, 12,  0,  0, 31, 43, 41, 53, 52],\n","        [43,  2,  0, 16, 43, 39, 58, 46,  6,  1, 58, 46, 39, 58,  1, 46, 39, 58,\n","         46,  1, 57, 59, 41, 49,  5, 42,  1, 58, 46, 43,  1, 46],\n","        [59, 39, 56, 56, 43, 50,  1, 61, 39, 57,  6,  1, 39, 52, 42,  1, 59, 56,\n","         45, 43, 42,  1, 61, 47, 58, 46, 39, 50,  0, 37, 53, 59],\n","        [39, 52, 42,  1, 45, 39, 56, 50, 47, 41, 10,  1, 57, 39, 63,  1, 58, 46,\n","         39, 58,  1, 21,  1, 57, 39, 47, 42,  1, 57, 53,  8,  1],\n","        [ 1, 50, 43, 58,  1, 63, 53, 59, 56,  1, 45, 43, 52, 43, 56, 39, 50,  0,\n","         42, 53,  1, 46, 47, 57,  1, 61, 53, 56, 57, 58,  8,  1],\n","        [57, 43,  6,  1, 39, 52, 42,  1, 54, 50, 59, 41, 49,  1, 46, 47, 51,  1,\n","         58, 46, 43, 52, 41, 43, 10,  0, 24, 43, 57, 58,  1, 46],\n","        [43, 57, 58,  1, 47, 52,  1, 58, 46, 47, 57,  1, 51, 39, 52,  6,  1, 39,\n","         57,  1, 21,  1, 51, 39, 63,  1, 57, 39, 63,  6,  1, 43],\n","        [21, 27, 10,  0, 37, 43, 57,  6,  1, 51, 39, 56, 56, 63,  6,  1, 42, 47,\n","         42,  1, 21,  1, 40, 59, 58,  1, 21,  1, 61, 39, 57,  1],\n","        [41, 50, 43, 39, 52, 57, 43, 42,  1, 51, 63,  1, 40, 53, 57, 53, 51,  6,\n","          1, 21,  1, 44, 56, 53, 51,  1, 58, 46, 43, 43,  1, 42],\n","        [10,  0, 27,  1, 46, 53, 50, 63,  1, 44, 56, 47, 39, 56,  6,  1, 27,  6,\n","          1, 58, 43, 50, 50,  1, 51, 43,  6,  1, 46, 53, 50, 63],\n","        [ 1, 41, 39, 52, 52, 53, 58,  1, 42, 47, 57, 47, 52, 46, 43, 56, 47, 58,\n","          1, 51, 43, 10,  0, 21, 44,  1, 63, 53, 59,  1, 40, 43]],\n","       device='cuda:0')\n","targets:\n","torch.Size([16, 32])\n","tensor([[52, 42,  1, 52, 53, 61, 12,  1, 61, 46, 43, 56, 43,  1, 40, 43,  1, 58,\n","         46, 63,  1, 40, 56, 53, 58, 46, 43, 56, 57, 12,  0, 35],\n","        [ 1, 57, 43, 43, 49,  6,  1, 39, 52, 42,  1, 49, 52, 53, 61,  1, 46, 53,\n","         61,  1, 58, 46, 47, 57,  1, 44, 53, 59, 50,  1, 51, 59],\n","        [ 1, 56, 39, 47, 50,  1, 47, 52,  0, 46, 47, 57,  1, 56, 53, 54, 43,  7,\n","         58, 56, 47, 41, 49, 57,  8,  1, 21,  5, 50, 50,  1, 58],\n","        [52, 42,  1, 43, 52, 58, 56, 43, 39, 58,  1, 58, 46, 43, 51,  6,  0, 18,\n","         53, 56,  1, 51, 63,  1, 61, 53, 59, 52, 42, 57,  5,  1],\n","        [43, 56, 43,  1, 41, 53, 51, 43, 57,  1, 30, 53, 51, 43, 53,  6,  1, 46,\n","         43, 56, 43,  1, 41, 53, 51, 43, 57,  1, 30, 53, 51, 43],\n","        [58,  1, 58, 46, 53, 59,  1, 44, 43, 43, 50,  1, 58, 46, 63, 57, 43, 50,\n","         44,  1, 52, 53, 61, 12,  0,  0, 31, 43, 41, 53, 52, 42],\n","        [ 2,  0, 16, 43, 39, 58, 46,  6,  1, 58, 46, 39, 58,  1, 46, 39, 58, 46,\n","          1, 57, 59, 41, 49,  5, 42,  1, 58, 46, 43,  1, 46, 53],\n","        [39, 56, 56, 43, 50,  1, 61, 39, 57,  6,  1, 39, 52, 42,  1, 59, 56, 45,\n","         43, 42,  1, 61, 47, 58, 46, 39, 50,  0, 37, 53, 59, 56],\n","        [52, 42,  1, 45, 39, 56, 50, 47, 41, 10,  1, 57, 39, 63,  1, 58, 46, 39,\n","         58,  1, 21,  1, 57, 39, 47, 42,  1, 57, 53,  8,  1, 18],\n","        [50, 43, 58,  1, 63, 53, 59, 56,  1, 45, 43, 52, 43, 56, 39, 50,  0, 42,\n","         53,  1, 46, 47, 57,  1, 61, 53, 56, 57, 58,  8,  1, 18],\n","        [43,  6,  1, 39, 52, 42,  1, 54, 50, 59, 41, 49,  1, 46, 47, 51,  1, 58,\n","         46, 43, 52, 41, 43, 10,  0, 24, 43, 57, 58,  1, 46, 47],\n","        [57, 58,  1, 47, 52,  1, 58, 46, 47, 57,  1, 51, 39, 52,  6,  1, 39, 57,\n","          1, 21,  1, 51, 39, 63,  1, 57, 39, 63,  6,  1, 43, 60],\n","        [27, 10,  0, 37, 43, 57,  6,  1, 51, 39, 56, 56, 63,  6,  1, 42, 47, 42,\n","          1, 21,  1, 40, 59, 58,  1, 21,  1, 61, 39, 57,  1, 44],\n","        [50, 43, 39, 52, 57, 43, 42,  1, 51, 63,  1, 40, 53, 57, 53, 51,  6,  1,\n","         21,  1, 44, 56, 53, 51,  1, 58, 46, 43, 43,  1, 42, 43],\n","        [ 0, 27,  1, 46, 53, 50, 63,  1, 44, 56, 47, 39, 56,  6,  1, 27,  6,  1,\n","         58, 43, 50, 50,  1, 51, 43,  6,  1, 46, 53, 50, 63,  1],\n","        [41, 39, 52, 52, 53, 58,  1, 42, 47, 57, 47, 52, 46, 43, 56, 47, 58,  1,\n","         51, 43, 10,  0, 21, 44,  1, 63, 53, 59,  1, 40, 43,  1]],\n","       device='cuda:0')\n","----\n","when input is [39] the target: 52\n","when input is [39, 52] the target: 42\n","when input is [39, 52, 42] the target: 1\n","when input is [39, 52, 42, 1] the target: 52\n","when input is [39, 52, 42, 1, 52] the target: 53\n","when input is [39, 52, 42, 1, 52, 53] the target: 61\n","when input is [39, 52, 42, 1, 52, 53, 61] the target: 12\n","when input is [39, 52, 42, 1, 52, 53, 61, 12] the target: 1\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1] the target: 61\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61] the target: 46\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46] the target: 43\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43] the target: 56\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56] the target: 43\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43] the target: 1\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1] the target: 40\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40] the target: 43\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43] the target: 1\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1] the target: 58\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58] the target: 46\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46] the target: 63\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63] the target: 1\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63, 1] the target: 40\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63, 1, 40] the target: 56\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63, 1, 40, 56] the target: 53\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63, 1, 40, 56, 53] the target: 58\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63, 1, 40, 56, 53, 58] the target: 46\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63, 1, 40, 56, 53, 58, 46] the target: 43\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63, 1, 40, 56, 53, 58, 46, 43] the target: 56\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63, 1, 40, 56, 53, 58, 46, 43, 56] the target: 57\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63, 1, 40, 56, 53, 58, 46, 43, 56, 57] the target: 12\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63, 1, 40, 56, 53, 58, 46, 43, 56, 57, 12] the target: 0\n","when input is [39, 52, 42, 1, 52, 53, 61, 12, 1, 61, 46, 43, 56, 43, 1, 40, 43, 1, 58, 46, 63, 1, 40, 56, 53, 58, 46, 43, 56, 57, 12, 0] the target: 35\n"]}],"source":["# testing get_batch function\n","\n","xb, yb = get_batch('train')\n","print('inputs:')\n","print(xb.shape)\n","print(xb)\n","print('targets:')\n","print(yb.shape)\n","print(yb)\n","\n","print('----')\n","\n","for b in range(batch_size): # batch dimension\n","    for t in range(n_ctx): # time dimension\n","        context = xb[b, :t+1]\n","        target = yb[b,t]\n","        if b == 0:\n","            print(f\"when input is {context.tolist()} the target: {target}\")"]},{"cell_type":"markdown","id":"9d7933c5-1836-439d-af2e-d9257395d76f","metadata":{"id":"9d7933c5-1836-439d-af2e-d9257395d76f"},"source":["## Построение упрощенной модели GPT"]},{"cell_type":"code","execution_count":null,"id":"c78f8f8d-4a2a-4f32-82b3-297668883e94","metadata":{"id":"c78f8f8d-4a2a-4f32-82b3-297668883e94"},"outputs":[],"source":["# loss function definition\n","@torch.no_grad()\n","def estimate_loss(model):\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(config[\"eval_iters\"])\n","        for k in range(config[\"eval_iters\"]):\n","            X, Y = get_batch(split)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out"]},{"cell_type":"markdown","id":"af01ffef-0409-425d-86b7-3ac546861f08","metadata":{"id":"af01ffef-0409-425d-86b7-3ac546861f08"},"source":["### Attention блоки"]},{"cell_type":"markdown","id":"b06ce45d-3018-45d0-a263-7e53fcf8551c","metadata":{"id":"b06ce45d-3018-45d0-a263-7e53fcf8551c"},"source":["Заметки о внимании от А. Карпатного:\n","- Внимание - это **механизм коммуникации**. Можно рассматривать как узлы в ориентированном графе, смотрящие друг на друга и агрегирующие информацию со взвешенной суммой от всех узлов, которые указывают на них, с весами, зависящими от данных.\n","- Здесь нет понятия пространства. Внимание просто действует по набору векторов. Вот почему нам нужно позиционно кодировать токены.\n","- Каждый пример в пакетном измерении, конечно, обрабатывается полностью независимо и никогда не \"разговаривает\" друг с другом\n","- В блоке внимания \"encoder\" просто удалите единственную строку, которая выполняет маскировку с помощью \"tril\", позволяя всем токенам взаимодействовать. Этот блок здесь называется блоком внимания \"декодер\", потому что он имеет треугольную маскировку и обычно используется в настройках авторегрессии, таких как языковое моделирование.\n","- \"само-внимание\" просто означает, что ключи и значения создаются из того же источника, что и запросы. При \"перекрестном внимании\" запросы по-прежнему генерируются из x, но ключи и значения поступают из какого-то другого внешнего источника (например, модуля кодирования).\n","- \"Масштабированное\" внимание дополнительно делит `wei` на 1/ sqrt(head_size). Это делает так, что когда входные данные Q, K являются единичной дисперсией, wei тоже будет единичной дисперсией, а Softmax останется рассеянным и не будет насыщать слишком сильно. Иллюстрация ниже.\n","  \n","`torch.tril` определяет нижнюю треугольную матрицу, используемую для создания маскировки. Код для модуля Multihead Attention следующий."]},{"cell_type":"code","execution_count":null,"id":"dd3f3f31","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"67236dba41c5289d97aef9229f12cf77","grade":true,"grade_id":"cell-2de34853f80c2e4f","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"dd3f3f31"},"outputs":[],"source":["class Head(nn.Module):\n","    \"\"\" Один блок внимания в механизме само-внимания (self-attention) \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","\n","        # Устанавливаем атрибуты класса на основе переданных аргументов\n","        for key, value in kwargs.items():\n","            setattr(self, key, value)\n","\n","        # Создаем линейные преобразователи для ключей (key), запросов (query) и значений (value)\n","        self.key = nn.Linear(self.n_embd, self.head_size, bias=False)\n","        self.query = nn.Linear(self.n_embd, self.head_size, bias=False)\n","        self.value = nn.Linear(self.n_embd, self.head_size, bias=False)\n","\n","        # Регистрируем буфер 'tril', который содержит нижний треугольник матрицы\n","        # с единицами на главной диагонали\n","        self.register_buffer('tril', torch.tril(torch.ones(self.n_ctx, self.n_ctx)))\n","\n","        # Создаем слой Dropout\n","        self.dropout = nn.Dropout(self.dropout)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Задание 1 (2 балла): Вам предоставлен код класса Head, который представляет собой один блок механизма само-внимания в трансформере.\n","\n","        Вам необходимо реализовать метод forward, который выполняет операцию само-внимания.\n","        Метод должен принимать входной тензор x формы (B, T, C), где B - размер пакета, T - количество токенов и\n","        C - размерность эмбеддингов.\n","        Вам нужно выполнить следующие шаги:\n","\n","        Преобразовать входной тензор x с помощью линейных преобразователей для ключей (сохранить в переменную k)\n","        и запросов (сохранить в переменную q) .\n","        Вычислить оценки внимания (affinities) с помощью матричного умножения ключей и запросов.\n","        Применить маску для маскирования верхнего треугольника матрицы оценок внимания.\n","        Применить функцию Softmax для получения весов внимания.\n","        Применить слой Dropout к весам внимания.\n","        Выполнить взвешенную агрегацию значений с использованием весов внимания (сохранить в переменную v).\n","        Реализуйте метод forward так, чтобы он возвращал результат операции само-внимания.\n","        \"\"\"\n","        # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","        B, T, C = x.size()\n","        k = self.key(x)\n","        q = self.query(x)\n","        affinities = q @ k.transpose(-2, -1) * C**-0.5\n","        masked = affinities.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n","        attnw = F.softmax(masked, dim=-1)\n","        attnw = self.dropout(attnw)\n","        v = self.value(x)\n","        out = attnw @ v\n","        # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n","        return out  # Возвращаем результат"]},{"cell_type":"code","execution_count":null,"id":"465d4d86-77ff-4acf-83f0-eff0f23a260d","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"27092ebfe282d450f4fce88e1bcda48c","grade":true,"grade_id":"cell-6785bb05d8a637eb","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"465d4d86-77ff-4acf-83f0-eff0f23a260d"},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    \"\"\" Несколько блоков механизма само-внимания, работающих параллельно \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","\n","        # Устанавливаем атрибуты класса на основе переданных аргументов\n","        for key, value in kwargs.items():\n","            setattr(self, key, value)\n","\n","        # Создаем список блоков Head (блоки механизма само-внимания) в количестве n_head\n","        self.heads = nn.ModuleList([Head(**kwargs) for _ in range(self.n_head)])\n","\n","        # Создаем линейный проецирующий слой для объединения результатов от разных голов\n","        self.proj = nn.Linear(self.n_embd, self.n_embd)\n","\n","        # Создаем слой Dropout\n","        self.dropout = nn.Dropout(self.dropout)\n","\n","    def forward(self, x):\n","        # Для каждой головы механизма само-внимания выполняем операцию self-attention\n","        # и конкатенируем результаты\n","\n","        \"\"\"\n","        Задание 2 (1 балл): Вам предоставлен код класса MultiHeadAttention, который представляет собой блок многоголового механизма само-внимания в трансформере.\n","        Вам нужно реализовать метод forward, который выполняет операцию многоголового само-внимания.\n","        Метод должен принимать входной тензор x формы (B, T, C), где B - размер пакета, T - количество токенов и\n","        C - размерность эмбеддингов. Вам нужно выполнить следующие шаги:\n","\n","        Передать входной тензор x через каждую голову многоголового механизма само-внимания.\n","        Конкатенировать результаты от каждой головы вдоль последней размерности.\n","        Пропустить объединенные результаты через линейный проецирующий слой.\n","        Применить слой Dropout к выходу проецирующего слоя.\n","        Реализуйте метод forward так, чтобы он возвращал итоговый результат операции многоголового само-внимания.\n","        \"\"\"\n","\n","        # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","        heads = torch.cat([h(x) for h in self.heads], dim=-1)\n","        out = self.dropout(self.proj(heads))\n","        # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n","\n","        return out  # Возвращаем итоговый результат"]},{"cell_type":"markdown","id":"4083ec61-51bb-4c19-ab1e-cf8c73932b8a","metadata":{"id":"4083ec61-51bb-4c19-ab1e-cf8c73932b8a"},"source":["Следующая ячейка содержит реализацию блока GPT Transformer, как показано в оригинальной статье. Это модуль ** декодера **, хотя он больше похож на модуль ** кодера ** трансформатора. Исходная архитектура использует 12 таких блоков, наша реализация использует 4 блока по умолчанию.\n","<center>\n","\n","![Alt text](block.png)\n","\n","</center>"]},{"cell_type":"code","execution_count":null,"id":"62006800","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"77ab9d31458fc43dba4f78f4b93facba","grade":true,"grade_id":"cell-75abc65d8ef470ef","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"62006800"},"outputs":[],"source":["class FeedFoward(nn.Module):\n","    \"\"\" Простой блок с линейным слоем, за которым следует нелинейное преобразование \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","\n","        # Устанавливаем атрибуты класса на основе переданных аргументов\n","        for key, value in kwargs.items():\n","            setattr(self, key, value)\n","\n","        # Создаем последовательный нейронный блок (нейронную сеть)\n","        self.net = nn.Sequential(\n","            nn.Linear(self.n_embd, 4 * self.n_embd),  # Линейный слой с увеличением размерности\n","            nn.ReLU(),  # Функция активации ReLU\n","            nn.Linear(4 * self.n_embd, self.n_embd),  # Линейный слой с уменьшением размерности\n","            nn.Dropout(self.dropout),  # Слой Dropout для регуляризации\n","        )\n","\n","    def forward(self, x):\n","        # Пропускаем входной тензор через нейронный блок (нейронную сеть)\n","\n","        \"\"\"\n","        Задание 3 (1 балл):\n","        Вам предоставлен код класса FeedFoward, который представляет собой простой блок в трансформере.\n","        Ваша задача - написать метод forward для этого класса. Метод forward принимает входной тензор x и должен выполнить следующие шаги:\n","\n","        Пропустить входной тензор через линейный слой с увеличением размерности в 4 раза.\n","        Применить функцию активации ReLU к результатам линейного слоя.\n","        Пропустить результаты через второй линейный слой с уменьшением размерности до исходной размерности.\n","        Применить слой Dropout для регуляризации данных.\n","        Вернуть результат после обработки.\n","        Напишите метод forward так, чтобы он выполнял описанные выше операции.\n","        \"\"\"\n","\n","        # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","        return self.net(x)\n","        # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n"]},{"cell_type":"code","execution_count":null,"id":"b8399ca2","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"b4ef619c97d73e6850363b23269d8c8e","grade":true,"grade_id":"cell-5eca5bae1dadd16d","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"b8399ca2"},"outputs":[],"source":["class Block(nn.Module):\n","    \"\"\" Блок трансформера: коммуникация, затем вычисления \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        # n_embd: размерность векторных представлений, n_head: количество \"голов\" внимания\n","        super().__init__()\n","\n","        # Устанавливаем атрибуты класса на основе переданных аргументов\n","        for key, value in kwargs.items():\n","            setattr(self, key, value)\n","\n","        # Создаем блок многоголового механизма само-внимания (self-attention)\n","        self.sa = MultiHeadAttention(**kwargs)\n","\n","        # Создаем блок с нейронной сетью для вычислений\n","        self.ffwd = FeedFoward(**kwargs)\n","\n","        # Создаем слои нормализации после каждого блока\n","        self.ln1 = nn.LayerNorm(self.n_embd)\n","        self.ln2 = nn.LayerNorm(self.n_embd)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Задание 4 (2 балла):\n","        Вам предоставлен код класса Block, который представляет собой блок в трансформере.\n","        Ваша задача - написать метод forward для этого класса. Метод forward выполняет следующие операции:\n","\n","        Проходит входной тензор через блок многоголового механизма само-внимания (self.sa) и добавляет результат к исходному тензору, а затем применяет слой нормализации.\n","        Проходит обновленный тензор через блок вычислений (self.ffwd), добавляет результат к предыдущему тензору и снова применяет слой нормализации.\n","        Возвращает итоговый тензор после всех операций.\n","        Ваше задание - реализовать метод forward так, чтобы он выполнял описанные выше операции.\n","        \"\"\"\n","        # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","        x = x + self.sa(self.ln1(x))\n","        x = x + self.ffwd(self.ln2(x))\n","        # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n","\n","        return x  # Возвращаем итоговый тензор после всех операций\n"]},{"cell_type":"markdown","id":"e894fdf8-b352-457c-a278-bb0bf01014c6","metadata":{"id":"e894fdf8-b352-457c-a278-bb0bf01014c6"},"source":["### Сборка языковой модели"]},{"cell_type":"markdown","id":"a241e725-d5d4-4594-bb44-07b03e8376a1","metadata":{"id":"a241e725-d5d4-4594-bb44-07b03e8376a1"},"source":["\n","Модели, которые назначают вероятности последовательностям слов, называются **языковыми моделями**. Начиная с задачи вычисления $\\mathrm{P}(w \\mid h)$, вероятности *слова* $w$ при заданной *истории* $h$, можно рассмотреть историю $h$ = \"нагреватель такой горячий, что\" и вероятность того, что следующее слово - \"нагреватель\"\n","\n","$$\n","\\mathrm{P}(\\text{нагреватель} \\mid \\text{нагреватель такой горячий, что})\n","$$\n","\n","и вычислить ее как относительные частоты: взять очень большой корпус, посчитать количество случаев, когда мы видим \"нагреватель такой горячий, что\",\n","и посчитать количество случаев, когда за ним следует \"нагреватель\". Однако это не всегда выполнимо. Обычно используются *наивные методы*, что подразумевает использование упрощений.\n","\n","**Биграммная модель** легко реализуется, но является очень наивной. Например, она аппроксимирует вероятность слова $w_n$ при заданных предыдущих словах\n","\n","$$\n","\\mathrm{P}(w_n \\mid w_1, w_2, \\dots, w_{n−1})\n","$$\n","\n","используя только условную вероятность предшествующего слова $P(w_n \\mid w_{n−1})$. Другими словами, вместо вычисления вероятности\n","\n","$$\n","\\mathrm{P}(\\text{нагреватель} \\mid \\text{основной нагреватель такой горячий, что})\\,,\n","$$\n","\n","мы аппроксимируем ее вероятностью\n","\n","$$\n","\\mathrm{P}(\\text{нагреватель} \\mid \\text{что})\\,.\n","$$"]},{"cell_type":"code","execution_count":null,"id":"218eeaf4-86b0-470f-840e-58a648b73c8e","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"39b11ca40da1d34991e94a6d57b28a35","grade":true,"grade_id":"cell-51203e3aec479b8e","locked":false,"points":0,"schema_version":3,"solution":true,"task":false},"id":"218eeaf4-86b0-470f-840e-58a648b73c8e"},"outputs":[],"source":["class GPTModel(nn.Module):\n","\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","\n","        # Устанавливаем атрибуты класса на основе переданных аргументов\n","        for key, value in kwargs.items():\n","            setattr(self, key, value)\n","\n","        # Создаем таблицу для эмбеддингов токенов\n","        self.token_embedding_table = nn.Embedding(self.vocab_size, self.n_embd)\n","\n","        # Создаем таблицу для позиционных эмбеддингов\n","        self.position_embedding_table = nn.Embedding(self.n_ctx, self.n_embd)\n","\n","        # Создаем последовательность блоков трансформера\n","        self.blocks = nn.Sequential(*[Block(**kwargs) for _ in range(self.n_layer)])\n","\n","        # Создаем слой нормализации после последнего блока\n","        self.ln_f = nn.LayerNorm(self.n_embd)\n","\n","        # Создаем линейный слой для преобразования в логиты\n","        self.lm_head = nn.Linear(self.n_embd, self.vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","        \"\"\"\n","        Задание 5 (4 балла):\n","        Вам предоставлен код класса GPTModel, который представляет собой модель на основе архитектуры GPT (Generative Pre-trained Transformer).\n","        Ваша задача - реализовать метод forward для этого класса. Метод forward принимает входной тензор idx и, при необходимости, целевой тензор targets.\n","\n","        Ваша задача - выполнять следующие операции в методе forward:\n","\n","        Получить эмбеддинги токенов (tok_emb) из таблицы эмбеддингов для токенов.\n","        Получить позиционные эмбеддинги (pos_emb) из таблицы позиционных эмбеддингов.\n","        Объединить эмбеддинги токенов и позиционные эмбеддинги, добавляя их друг к другу, и сохранить результат в тензор x.\n","        Проходить тензор x через последовательность блоков трансформера (self.blocks).\n","        Применить слой нормализации (self.ln_f) к выходу из блоков.\n","        Проходить выход через линейный слой self.lm_head для получения логитов (logits) для каждого токена.\n","        Если вам предоставлены целевые токены (targets), вам также нужно рассчитать функцию потерь, используя кросс-энтропию (F.cross_entropy)\n","        между логитами и целевыми токенами.\n","\n","        Возвращайте logits и loss.\n","        \"\"\"\n","        # НАЧАЛО ВАШЕГО РЕШЕНИЯ\n","        B, T = idx.size()\n","        tok_emb = self.token_embedding_table(idx)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n","        x = tok_emb + pos_emb\n","        x = self.blocks(x)\n","        x = self.ln_f(x)\n","        logits = self.lm_head(x)\n","        if targets is not None:\n","            B, T, C = logits.size()\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","        else:\n","            loss = None\n","        # КОНЕЦ ВАШЕГО РЕШЕНИЯ\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx - это массив (B, T) с индексами в текущем контексте\n","        for _ in range(max_new_tokens):\n","            # Обрезаем idx до последних токенов размером n_ctx\n","            idx_cond = idx[:, -self.n_ctx:]\n","            # Получаем прогнозы\n","            logits, loss = self(idx_cond)\n","            # Сосредотачиваемся только на последнем шаге времени\n","            logits = logits[:, -1, :]  # становится (B, C)\n","            # Применяем софтмакс для получения вероятностей\n","            probs = F.softmax(logits, dim=-1)  # (B, C)\n","            # Сэмплируем из распределения\n","            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n","            # Добавляем выбранный индекс к текущей последовательности\n","            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n","        return idx\n"]},{"cell_type":"code","execution_count":null,"id":"3d2dfd12-1a70-4ca0-8e51-9d109effab35","metadata":{"id":"3d2dfd12-1a70-4ca0-8e51-9d109effab35","colab":{"base_uri":"https://localhost:8080/"},"outputId":"04ce1304-2dd2-4ef4-fbb6-f7b7359eed6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.209729 M parameters\n"]}],"source":["# Создание экземпляра модели с параметрами, переданными через `config`\n","model = GPTModel(**config)\n","\n","# Перенос модели на указанное устройство (например, GPU)\n","m = model.to(device)\n","\n","# Создание оптимизатора AdamW для обучения модели с заданной скоростью обучения (learning_rate)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"])\n","\n","# Вывод количества параметров в модели в миллионах (1e6)\n","print(sum(p.numel() for p in m.parameters()) / 1e6, 'M parameters')"]},{"cell_type":"code","execution_count":null,"id":"5d75db41-46cf-477a-9a4b-f6c530d468a7","metadata":{"id":"5d75db41-46cf-477a-9a4b-f6c530d468a7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a346c8f6-ef50-4235-ed56-09a91f6a8653"},"outputs":[{"output_type":"stream","name":"stdout","text":["шаг 0: потери на обучении 4.3297, потери на валидации 4.3325\n","шаг 100: потери на обучении 2.6701, потери на валидации 2.6749\n","шаг 200: потери на обучении 2.4939, потери на валидации 2.5115\n","шаг 300: потери на обучении 2.4181, потери на валидации 2.4278\n","шаг 400: потери на обучении 2.3582, потери на валидации 2.3705\n","шаг 500: потери на обучении 2.3099, потери на валидации 2.3153\n","шаг 600: потери на обучении 2.2536, потери на валидации 2.2802\n","шаг 700: потери на обучении 2.2126, потери на валидации 2.2269\n","шаг 800: потери на обучении 2.1705, потери на валидации 2.1926\n","шаг 900: потери на обучении 2.1088, потери на валидации 2.1478\n","шаг 1000: потери на обучении 2.0844, потери на валидации 2.1194\n","шаг 1100: потери на обучении 2.0611, потери на валидации 2.1002\n","шаг 1200: потери на обучении 2.0308, потери на валидации 2.1064\n","шаг 1300: потери на обучении 1.9945, потери на валидации 2.0599\n","шаг 1400: потери на обучении 1.9861, потери на валидации 2.0538\n","шаг 1500: потери на обучении 1.9509, потери на валидации 2.0378\n","шаг 1600: потери на обучении 1.9352, потери на валидации 2.0126\n","шаг 1700: потери на обучении 1.9238, потери на валидации 2.0154\n","шаг 1800: потери на обучении 1.8800, потери на валидации 1.9867\n","шаг 1900: потери на обучении 1.8886, потери на валидации 1.9871\n","шаг 2000: потери на обучении 1.8697, потери на валидации 1.9778\n","шаг 2100: потери на обучении 1.8749, потери на валидации 1.9858\n","шаг 2200: потери на обучении 1.8454, потери на валидации 1.9463\n","шаг 2300: потери на обучении 1.8127, потери на валидации 1.9403\n","шаг 2400: потери на обучении 1.8173, потери на валидации 1.9406\n","шаг 2500: потери на обучении 1.8097, потери на валидации 1.9191\n","шаг 2600: потери на обучении 1.7691, потери на валидации 1.8991\n","шаг 2700: потери на обучении 1.7893, потери на валидации 1.9192\n","шаг 2800: потери на обучении 1.7762, потери на валидации 1.8880\n","шаг 2900: потери на обучении 1.7651, потери на валидации 1.9038\n","шаг 3000: потери на обучении 1.7795, потери на валидации 1.9051\n","шаг 3100: потери на обучении 1.7567, потери на валидации 1.8687\n","шаг 3200: потери на обучении 1.7467, потери на валидации 1.8612\n","шаг 3300: потери на обучении 1.7264, потери на валидации 1.8802\n","шаг 3400: потери на обучении 1.7341, потери на валидации 1.8789\n","шаг 3500: потери на обучении 1.7163, потери на валидации 1.8744\n","шаг 3600: потери на обучении 1.7178, потери на валидации 1.8649\n","шаг 3700: потери на обучении 1.7067, потери на валидации 1.8495\n","шаг 3800: потери на обучении 1.7210, потери на валидации 1.8604\n","шаг 3900: потери на обучении 1.7021, потери на валидации 1.8512\n","шаг 4000: потери на обучении 1.7093, потери на валидации 1.8493\n","шаг 4100: потери на обучении 1.6895, потери на валидации 1.8381\n","шаг 4200: потери на обучении 1.6963, потери на валидации 1.8322\n","шаг 4300: потери на обучении 1.6837, потери на валидации 1.8316\n","шаг 4400: потери на обучении 1.6797, потери на валидации 1.8223\n","шаг 4500: потери на обучении 1.6776, потери на валидации 1.8435\n","шаг 4600: потери на обучении 1.6758, потери на валидации 1.8219\n","шаг 4700: потери на обучении 1.6674, потери на валидации 1.8168\n","шаг 4800: потери на обучении 1.6698, потери на валидации 1.8194\n","шаг 4900: потери на обучении 1.6542, потери на валидации 1.8065\n","шаг 4999: потери на обучении 1.6451, потери на валидации 1.8225\n"]}],"source":["max_iters = 5000  # Количество итераций обучения\n","\n","# Запуск цикла обучения на заданное количество итераций\n","for iter in range(max_iters):\n","\n","    # Периодически оцениваем потери на обучающем и валидационном наборах данных\n","    if iter % config[\"eval_interval\"] == 0 or iter == max_iters - 1:\n","        # Оценка потерь путем вызова функции estimate_loss с использованием модели\n","        losses = estimate_loss(model)\n","        # Выводим информацию о потерях на обучающем и валидационном наборах данных\n","        print(f\"шаг {iter}: потери на обучении {losses['train']:.4f}, потери на валидации {losses['val']:.4f}\")\n","\n","    # Получаем пакет данных (xb - входные данные, yb - целевые значения)\n","    xb, yb = get_batch('train')\n","\n","    # Вычисляем логиты и потери, вызывая модель с входными данными\n","    logits, loss = model(idx=xb, targets=yb)\n","\n","    # Обнуляем градиенты оптимизатора с помощью optimizer.zero_grad(set_to_none=True)\n","    optimizer.zero_grad(set_to_none=True)\n","\n","    # Вычисляем градиенты потерь относительно параметров модели\n","    loss.backward()\n","\n","    # Обновляем параметры модели с использованием оптимизатора\n","    optimizer.step()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}