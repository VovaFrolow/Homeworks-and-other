Репозиторий содержит прорешанные домашние задания по курсу Deep Learning от DLS МФТИ. 

Простые работы.
1. Основы машинного обучения. Обучен классификатор K-Nearest Neighbors с применением Grid Search и средств библиотек pandas, sklearn. 
2. Линейные модели и методы оптимизации. Реализована функция градиентного спуска, генератор батчей, класс для логистической регрессии и логистической регрессии с регуляризацией (l1 и l2). Класс для логистической регрессии с регуляризацией был протестирован обучением на сгенерированных данных и обучением на датасете MNIST с применением кросс-валидации.
3. ML-задача. Проанализированы табличные данные с помощью pandas и matplotlib. Реализован pipeline для предобработки данных (нормализация числовых признаков и кодирование категориальных). Обучена логистическая регрессия из sklearn, а также обучен классификатор CatBoostClassifier и сделана посылка на Kaggle.
4. Свёрточные и полносвязные нейросети. Реализованы класс для логистической регрессии и цикл обучения на PyTorch. Сравнивались функции активации обучением трёхслойной нейронной сети на датасете MNIST. Произведены эксперименты с ядрами свёрток и обучена LeNet на MNIST.

Более объёмные и сложные работы.

5. Классификация Симпсонов. Реализованы класс датасета для загрузки изображений, цикл обучения, визуализация, аугментация данных, несколько архитектур свёрточных нейронных сетей с применением MaxPool, BatchNorm, Dropout, а также Fine tuning предобученной ResNet18. Сделан сабмит на Kaggle.
6. Сегментация изображений. Реализованы архитектуры SegNet и UNet, а также функции потерь Binary Cross Entropy, Dice loss, Focal loss, а также Correlation Maximized Structural Similarity loss по описанию из статьи. На перечисленных лоссах обучены SegNet и UNet, проведено сравнение качества сегментации по метрике IoU, что отражено в отчёте в конце ноутбука. 
7. Автоэнкодеры. Реализованы архитектуры Vanilla Autoencoder, Variational Autoencoder (VAE), Conditional VAE. Первая модель обучалась на фотографиях людей, осуществлена генерация фотографий с применением модели на основе случайного тензора, приведённого к латентному распределению. "Пририсованы" улыбки путём выделения "вектора улыбки" на основе латентного вектора для улыбающихся людей. Остальные две модели обучались на датасете MNIST, для них реализована функция loss vae, осуществлена латентная репрезентация в виде точек в двумерном пространстве с помощью sklearn и matplotlib. Прорешана бонусная часть. 
8. Generative Adversarial Networks (GAN). Реализованы архитектуры дискриминатора (классификатора) и генератора, обучена генеративно-состязательная модель, осуществлён сэмплинг, реализован подход к оценке качества генерации на основе KNN, визуализированы распределения реальных и сгенерированных изображений с помощью метода TSNE в sklearn, сделаны выводы.
9. Распознавание лиц (итоговый проект). Реализован пайплайн распознавания лиц, осуществлён Fine tuning предобученной Inception ResNet v1, реализована метрика TPR@FPR, обучена модель на Cross Entropy loss, Tripletloss и на имплементированном ArcFace.
10. Ранжирование текстов на основе эмбеддингов. Реализованы функция расчёта метрик HITS и DCG, функция ранжирования текстов на основе векторного представления слов. Обучена модель Word2Vec, проведено сравнение качества ранжирования на основе различных способов обработки, токенизаторов и эмбеддингов. 
11. Классификация текстов с помощью RNN. Реализованы архитектуры с обычными RNN- и LSTM-блоками, обучены модели классификация текстов с двумя подходами к аггрегации эмбеддингов - осреднение и максимизация. Проведено несколько экспериментов, результаты по которым отражены в выводах в самом ноутбуке.  
12. Языковое моделирование. Реализованы архитектуры с LSTM- и GRU-блоками, проведены эксперименты с различными подходами к оптимизации, а также с добавлением в архитектуру LayerNorm, дополнительных линейных слоёв и повышением размерности скрытого состояния. 
13. Seg_seism_img не относится к домашним заданиям с курсов и выполнялась самостоятельно для научно-исследовательской работы. Реализованы архитектуры UNet, UNet with Hypercolumns и UNet with Spatial and Channel ‘Squeeze & Excitation’ blocks. Также реализована функция потерь на основе IoU и упрощённой Binary Cross Entropy, метрика mIoU. Обучены модели сегментации геологических слоёв на сейсмических изображениях, результаты всех моделей сравнивались на инференсе. 
